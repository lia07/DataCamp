{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning Data in R.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPplt5lJCPysqS9XyWmVPid",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Cleaning_Data_in_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning Data in **R**"
      ],
      "metadata": {
        "id": "9SrfmXA9Rm72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1**"
      ],
      "metadata": {
        "id": "QauIz27jYAXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Examine the data types of the columns of bike_share_rides.\n",
        "Get a summary of the user_birth_year column of bike_share_rides.\n",
        "\n",
        "# Glimpse at bike_share_rides\n",
        "glimpse(bike_share_rides)\n",
        "\n",
        "# Summary of user_birth_year\n",
        "summary(bike_share_rides$user_birth_year)\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "50 XP\n",
        "3\n",
        "Add a new column to bike_share_rides called user_birth_year_fct, which contains user_birth_year, converted to a factor.\n",
        "Assert that the user_birth_year_fct is a factor to confirm the conversion.\n",
        "\n",
        "\n",
        "# Glimpse at bike_share_rides\n",
        "glimpse(bike_share_rides)\n",
        "\n",
        "# Summary of user_birth_year\n",
        "summary(bike_share_rides$user_birth_year)\n",
        "\n",
        "# Convert user_birth_year to factor: user_birth_year_fct\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  mutate(user_birth_year_fct = as.factor(user_birth_year))\n",
        "\n",
        "# Assert user_birth_year_fct is a factor\n",
        "assert_is_factor(bike_share_rides$user_birth_year_fct)\n",
        "\n",
        "# Summary of user_birth_year_fct\n",
        "summary(bike_share_rides$user_birth_year_fct)\n"
      ],
      "metadata": {
        "id": "dzzqhuR2RpeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Use str_remove() to remove \"minutes\" from the duration column of bike_share_rides. Add this as a new column called duration_trimmed.\n",
        "Convert the duration_trimmed column to a numeric type and add this as a new column called duration_mins.\n",
        "Glimpse at bike_share_rides and assert that the duration_mins column is numeric.\n",
        "Calculate the mean of duration_mins.\n",
        "\n",
        "\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  # Remove 'minutes' from duration: duration_trimmed\n",
        "  mutate(duration_trimmed = str_remove(duration, \"minutes\"),\n",
        "         # Convert duration_trimmed to numeric: duration_mins\n",
        "         duration_mins = as.numeric(duration_trimmed))\n",
        "\n",
        "# Glimpse at bike_share_rides\n",
        "glimpse(bike_share_rides)\n",
        "\n",
        "# Assert duration_mins is numeric\n",
        "assert_is_numeric(bike_share_rides$duration_mins)\n",
        "\n",
        "# Calculate mean duration\n",
        "mean(bike_share_rides$duration_mins)\n",
        "\n"
      ],
      "metadata": {
        "id": "gZ0e7vIhRrUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Create a three-bin histogram of the duration_min column of bike_share_rides using ggplot2 to identify if there is out-of-range data.\n",
        "\n",
        "# Create breaks\n",
        "breaks <- c(min(bike_share_rides$duration_min), 0, 1440, max(bike_share_rides$duration_min))\n",
        "\n",
        "# Create a histogram of duration_min\n",
        "ggplot(bike_share_rides, aes(duration_min)) +\n",
        "  geom_histogram(breaks = breaks)\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Replace the values of duration_min that are greater than 1440 minutes (24 hours) with 1440. Add this to bike_share_rides as a new column called duration_min_const.\n",
        "Assert that all values of duration_min_const are between 0 and 1440.\n",
        "\n",
        "\n",
        "# Create breaks\n",
        "breaks <- c(min(bike_share_rides$duration_min), 0, 1440, max(bike_share_rides$duration_min))\n",
        "\n",
        "# Create a histogram of duration_min\n",
        "ggplot(bike_share_rides, aes(duration_min)) +\n",
        "  geom_histogram(breaks = breaks)\n",
        "\n",
        "# duration_min_const: replace vals of duration_min > 1440 with 1440\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  mutate(duration_min_const = replace(duration_min, duration_min > 1440, 1440))\n",
        "\n",
        "# Make sure all values of duration_min_const are between 0 and 1440\n",
        "assert_all_are_in_closed_range(bike_share_rides$duration_min_const, lower = 0, upper = 1440)\n",
        "\n"
      ],
      "metadata": {
        "id": "R1HlIxueW-I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Convert the date column of bike_share_rides from character to the Date data type.\n",
        "Assert that all values in the date column happened sometime in the past and not in the future.\n",
        "Filter bike_share_rides to get only the rides from the past or today, and save this as bike_share_rides_past.\n",
        "Assert that the dates in bike_share_rides_past occurred only in the past.\n",
        "\n",
        "\n",
        "library(lubridate)\n",
        "# Convert date to Date type\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  mutate(date = as.Date(date))\n",
        "\n",
        "# Make sure all dates are in the past\n",
        "assert_all_are_in_past(bike_share_rides$date)\n",
        "\n",
        "# Filter for rides that occurred before or on today's date\n",
        "bike_share_rides_past <- bike_share_rides %>%\n",
        "  filter(date <= today())\n",
        "\n",
        "# Make sure all dates from bike_share_rides_past are in the past\n",
        "assert_all_are_in_past(bike_share_rides_past$date)\n"
      ],
      "metadata": {
        "id": "GRdoRlv3aDsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Convert the date column of bike_share_rides from character to the Date data type.\n",
        "Assert that all values in the date column happened sometime in the past and not in the future.\n",
        "Filter bike_share_rides to get only the rides from the past or today, and save this as bike_share_rides_past.\n",
        "Assert that the dates in bike_share_rides_past occurred only in the past.\n",
        "\n",
        "\n",
        "library(lubridate)\n",
        "# Convert date to Date type\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  mutate(date = as.Date(date))\n",
        "\n",
        "# Make sure all dates are in the past\n",
        "assert_all_are_in_past(bike_share_rides$date)\n",
        "\n",
        "# Filter for rides that occurred before or on today's date\n",
        "bike_share_rides_past <- bike_share_rides %>%\n",
        "  filter(date <= today())\n",
        "\n",
        "# Make sure all dates from bike_share_rides_past are in the past\n",
        "assert_all_are_in_past(bike_share_rides_past$date)\n"
      ],
      "metadata": {
        "id": "oJYpFxj8acjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Convert the date column of bike_share_rides from character to the Date data type.\n",
        "Assert that all values in the date column happened sometime in the past and not in the future.\n",
        "Filter bike_share_rides to get only the rides from the past or today, and save this as bike_share_rides_past.\n",
        "Assert that the dates in bike_share_rides_past occurred only in the past.\n",
        "\n",
        "\n",
        "library(lubridate)\n",
        "# Convert date to Date type\n",
        "bike_share_rides <- bike_share_rides %>%\n",
        "  mutate(date = as.Date(date))\n",
        "\n",
        "# Make sure all dates are in the past\n",
        "assert_all_are_in_past(bike_share_rides$date)\n",
        "\n",
        "# Filter for rides that occurred before or on today's date\n",
        "bike_share_rides_past <- bike_share_rides %>%\n",
        "  filter(date <= today())\n",
        "\n",
        "# Make sure all dates from bike_share_rides_past are in the past\n",
        "assert_all_are_in_past(bike_share_rides_past$date)\n"
      ],
      "metadata": {
        "id": "AT48rfRoW-F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Get the total number of full duplicates in bike_share_rides.\n",
        "Remove all full duplicates from bike_share_rides and save the new data frame as bike_share_rides_unique.\n",
        "Get the total number of full duplicates in the new bike_share_rides_unique data frame.\n",
        "\n",
        "\n",
        "# Count the number of full duplicates\n",
        "sum(duplicated(bike_share_rides))\n",
        "\n",
        "# Remove duplicates\n",
        "bike_share_rides_unique <- distinct(bike_share_rides)\n",
        "\n",
        "# Count the full duplicates in bike_share_rides_unique\n",
        "sum(duplicated(bike_share_rides_unique))\n"
      ],
      "metadata": {
        "id": "Ab16jI6TbL3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Count the number of occurrences of each ride_id.\n",
        "Filter for ride_ids that occur multiple times.\n",
        "\n",
        "# Find duplicated ride_ids\n",
        "bike_share_rides %>% \n",
        "  # Count the number of occurrences of each ride_id\n",
        "  count(ride_id) %>% \n",
        "  # Filter for rows with a count > 1\n",
        "  filter(n > 1)\n",
        "\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Remove full and partial duplicates from bike_share_rides based on ride_id only, keeping all columns.\n",
        "Store this as bike_share_rides_unique.\n",
        "\n",
        "\n",
        "# Find duplicated ride_ids\n",
        "bike_share_rides %>% \n",
        "  count(ride_id) %>% \n",
        "  filter(n > 1)\n",
        "\n",
        "# Remove full and partial duplicates\n",
        "bike_share_rides_unique <- bike_share_rides %>%\n",
        "  # Only based on ride_id instead of all cols\n",
        "  distinct(ride_id, .keep_all = TRUE)\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Find the duplicated ride_ids in bike_share_rides_unique.\n",
        "\n",
        "# Find duplicated ride_ids\n",
        "bike_share_rides %>% \n",
        "  count(ride_id) %>% \n",
        "  filter(n > 1)\n",
        "\n",
        "# Remove full and partial duplicates\n",
        "bike_share_rides_unique <- bike_share_rides %>%\n",
        "  # Only based on ride_id instead of all cols\n",
        "  distinct(ride_id, .keep_all = TRUE)\n",
        "\n",
        "# Find duplicated ride_ids in bike_share_rides_unique\n",
        "bike_share_rides_unique %>%\n",
        "  # Count the number of occurrences of each ride_id\n",
        "  count(ride_id) %>%\n",
        "  # Filter for rows with a count > 1\n",
        "  filter(n > 1)\n"
      ],
      "metadata": {
        "id": "558M03KTCIwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2**"
      ],
      "metadata": {
        "id": "k_zbChE4OkB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Group bike_share_rides by ride_id and date.\n",
        "Add a column called duration_min_avg that contains the mean ride duration for the row's ride_id and date.\n",
        "Remove duplicates based on ride_id and date, keeping all columns of the data frame.\n",
        "Remove the duration_min column.\n",
        "\n",
        "bike_share_rides %>%\n",
        "  # Group by ride_id and date\n",
        "  group_by(ride_id, date) %>%\n",
        "  # Add duration_min_avg column\n",
        "  mutate(duration_min_avg = mean(duration_min)) %>%\n",
        "  # Remove duplicates based on ride_id and date, keep all cols\n",
        "  distinct(ride_id, date, .keep_all = TRUE) %>%\n",
        "  # Remove duration_min column\n",
        "  select(-duration_min)\n",
        "  "
      ],
      "metadata": {
        "id": "QYQ1faiGCIs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 3/4\n",
        "50 XP\n",
        "3\n",
        "4\n",
        "Use the correct type of filtering join on the sfo_survey data frame and the dest_sizes data frame to get the rows of sfo_survey with invalid dest_size values.\n",
        "Get the id, airline, destination, and dest_size columns.\n",
        "\n",
        "\n",
        "# Find bad dest_size rows\n",
        "sfo_survey %>% \n",
        "  # Join with dest_sizes data frame to get bad dest_size rows\n",
        "  anti_join(dest_sizes, by = \"dest_size\") %>%\n",
        "  # Select id, airline, destination, and dest_size cols\n",
        "  select(id, airline, destination, dest_size)\n",
        "\n",
        "\n",
        "Instructions 4/4\n",
        "50 XP\n",
        "4\n",
        "Use the correct filtering join on sfo_survey and dest_sizes to get the rows of sfo_survey that have a valid dest_size.\n",
        "Count the number of times that each dest_size occurs to make sure there are no invalid values left behind.\n",
        "\n",
        "# Remove bad dest_size rows\n",
        "sfo_survey %>% \n",
        "  # Join with dest_sizes\n",
        "  semi_join(dest_sizes, by = \"dest_size\") %>%\n",
        "  # Count the number of each dest_size\n",
        "  count(dest_size)\n",
        "  "
      ],
      "metadata": {
        "id": "NtyZlZEHCIo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/4\n",
        "30 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Count the number of occurrences of each category of the dest_size variable of sfo_survey.\n",
        "\n",
        "# Count dest_size\n",
        "sfo_survey %>%\n",
        "  count(dest_size)\n",
        "\n",
        "\n",
        "Instructions 3/4\n",
        "0 XP\n",
        "4\n",
        "Count the number of occurrences of each category of the cleanliness variable of sfo_survey.\n",
        "\n",
        "\n",
        "# Count dest_size\n",
        "sfo_survey %>%\n",
        "  count(dest_size)\n",
        "\n",
        "# Count cleanliness\n",
        "sfo_survey %>%\n",
        "  count(cleanliness)"
      ],
      "metadata": {
        "id": "u55JpqpRCIlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Add a column to sfo_survey called dest_size_trimmed that contains the values in the dest_size column with all leading and trailing whitespace removed.\n",
        "Add another column called cleanliness_lower that contains the values in the cleanliness column converted to all lowercase.\n",
        "Count the number of occurrences of each category in dest_size_trimmed.\n",
        "Count the number of occurrences of each category in cleanliness_lower.\n",
        "\n",
        "# Add new columns to sfo_survey\n",
        "sfo_survey <- sfo_survey %>%\n",
        "  # dest_size_trimmed: dest_size without whitespace\n",
        "  mutate(dest_size_trimmed = str_trim(dest_size),\n",
        "         # cleanliness_lower: cleanliness converted to lowercase\n",
        "         cleanliness_lower = str_to_lower(cleanliness))\n",
        "\n",
        "# Count values of dest_size_trimmed\n",
        "sfo_survey %>%\n",
        "  count(dest_size_trimmed)\n",
        "\n",
        "# Count values of cleanliness_lower\n",
        "sfo_survey %>%\n",
        "  count(cleanliness_lower)\n",
        "  "
      ],
      "metadata": {
        "id": "6djgDK4fCIhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "0 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Count the categories of dest_region.\n",
        "\n",
        "# Count categories of dest_region\n",
        "sfo_survey %>%\n",
        "  count(dest_region)\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "100 XP\n",
        "3\n",
        "Create a vector called europe_categories containing the three values of dest_region that need to be collapsed.\n",
        "Add a new column to sfo_survey called dest_region_collapsed that contains the values from the dest_region column, except the categories stored in europe_categories should be collapsed to Europe.\n",
        "Count the categories of dest_region_collapsed.\n",
        "\n",
        "# Count categories of dest_region\n",
        "sfo_survey %>%\n",
        "  count(dest_region)\n",
        "\n",
        "# Categories to map to Europe\n",
        "europe_categories <- c(\"EU\", \"eur\", \"Europ\")\n",
        "\n",
        "# Add a new col dest_region_collapsed\n",
        "sfo_survey %>%\n",
        "  # Map all categories in europe_categories to Europe\n",
        "  mutate(dest_region_collapsed = fct_collapse(dest_region, \n",
        "                                              Europe = europe_categories)) %>%\n",
        "  # Count categories of dest_region_collapsed\n",
        "  count(dest_region_collapsed)\n",
        "  "
      ],
      "metadata": {
        "id": "PYzqmuScCIdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "Filter for rows with phone numbers that contain \"-\"s.\n",
        "\n",
        "# Filter for rows with \"-\" in the phone column\n",
        "sfo_survey %>%\n",
        "  filter(str_detect(phone, \"-\"))\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "35 XP\n",
        "Filter for rows with phone numbers that contain \"-\"s.\n",
        "2\n",
        "Filter for rows with phone numbers that contain \"(\", or \")\". Remember to use fixed() when searching for parentheses.\n",
        "\n",
        "# Filter for rows with \"(\" or \")\" in the phone column\n",
        "sfo_survey %>%\n",
        "  filter(str_detect(phone, fixed(\"(\")) | str_detect(phone, fixed(\")\")))\n",
        "\n"
      ],
      "metadata": {
        "id": "H2rNUywpRrSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Remove opening and closing parentheses from the phone column. Store this as a variable called phone_no_parens. Remember to use fixed()!\n",
        "\n",
        "# Remove parentheses from phone column\n",
        "phone_no_parens <- sfo_survey$phone %>%\n",
        "  # Remove \"(\"s\n",
        "  str_remove_all(fixed(\"(\")) %>%\n",
        "  # Remove \")\"s\n",
        "  str_remove_all(fixed(\")\"))\n",
        "\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Add a new column to sfo_survey called phone_no_parens that contains the contents of phone_no_parens.\n",
        "\n",
        "# Remove parentheses from phone column\n",
        "phone_no_parens <- sfo_survey$phone %>%\n",
        "  # Remove \"(\"s\n",
        "  str_remove_all(fixed(\"(\")) %>%\n",
        "  # Remove \")\"s\n",
        "  str_remove_all(fixed(\")\"))\n",
        "\n",
        "# Add phone_no_parens as column\n",
        "sfo_survey %>%\n",
        "  mutate(phone_no_parens = phone_no_parens)\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Create a new column of sfo_survey called phone_clean containing the values of phone_no_parens with all hyphens replaced with spaces.\n",
        "\n",
        "# Remove parentheses from phone column\n",
        "phone_no_parens <- sfo_survey$phone %>%\n",
        "  # Remove \"(\"s\n",
        "  str_remove_all(fixed(\"(\")) %>%\n",
        "  # Remove \")\"s\n",
        "  str_remove_all(fixed(\")\"))\n",
        "\n",
        "# Add phone_no_parens as column\n",
        "sfo_survey %>%\n",
        "  mutate(phone_no_parens = phone_no_parens,\n",
        "  # Replace all hyphens in phone_no_parens with spaces\n",
        "         phone_clean = str_replace_all(phone_no_parens, \"-\", \" \"))"
      ],
      "metadata": {
        "id": "Bgv5D29N37S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Examine the invalid phone numbers by filtering for numbers whose length is not equal to 12.\n",
        "Remove the rows with invalid numbers by filtering for numbers with a length of exactly 12.\n",
        "\n",
        "# Check out the invalid numbers\n",
        "sfo_survey %>%\n",
        "  filter(str_length(phone) != 12)\n",
        "\n",
        "# Remove rows with invalid numbers\n",
        "sfo_survey %>%\n",
        "  filter(str_length(phone) == 12)\n",
        "  "
      ],
      "metadata": {
        "id": "fZ8RtXtrRrFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3**"
      ],
      "metadata": {
        "id": "Y5XkGBi58JJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Take a look at the head of accounts to get a sense of the data you're working with.\n",
        "\n",
        "# Check out the accounts data frame\n",
        "accounts\n"
      ],
      "metadata": {
        "id": "-ULFwiWWRrCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Convert the dates in the date_opened column to the same format using the formats vector and store this as a new column called date_opened_clean.\n",
        "\n",
        "# Check out the accounts data frame\n",
        "head(accounts)\n",
        "\n",
        "# Define the date formats\n",
        "formats <- c(\"%Y-%m-%d\", \"%B %d, %Y\")\n",
        "\n",
        "# Convert dates to the same format\n",
        "accounts %>%\n",
        "  mutate(date_opened_clean = parse_date_time(date_opened, orders = formats))"
      ],
      "metadata": {
        "id": "qMIxLrvqRq9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/4\n",
        "20 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Create a scatter plot with date_opened on the x-axis and total on the y-axis.\n",
        "\n",
        "# Scatter plot of opening date and total amount\n",
        "accounts %>%\n",
        "  ggplot(aes(x = date_opened, y = total)) +\n",
        "  geom_point()\n",
        "\n",
        "Instructions 2/4\n",
        "20 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Left join accounts and account_offices by their id columns.\n",
        "\n",
        "\n",
        "# Scatter plot of opening date and total amount\n",
        "accounts %>%\n",
        "  ggplot(aes(x = date_opened, y = total)) +\n",
        "  geom_point()\n",
        "\n",
        "# Left join accounts and account_offices by id\n",
        "accounts %>%\n",
        "  left_join(account_offices, by = \"id\")\n",
        "\n",
        "\n",
        "Instructions 3/4\n",
        "0 XP\n",
        "4\n",
        "Convert the totals from the Tokyo office from yen to dollars, and keep the total from the New York office in dollars. Store this as a new column called total_usd.\n",
        "\n",
        "\n",
        "# Scatter plot of opening date and total amount\n",
        "accounts %>%\n",
        "  ggplot(aes(x = date_opened, y = total)) +\n",
        "  geom_point()\n",
        "\n",
        "# Left join accounts to account_offices by id\n",
        "accounts %>%\n",
        "  left_join(account_offices, by = \"id\") %>%\n",
        "  # Convert totals from the Tokyo office to USD\n",
        "  mutate(total_usd = ifelse(office == \"Tokyo\", total / 104, total))\n",
        "\n",
        "Instructions 4/4\n",
        "30 XP\n",
        "4\n",
        "Create a scatter plot of your new uniform data using date_opened on the x-axis and total_usd on the y-axis.\n",
        "\n",
        "# Scatter plot of opening date and total amount\n",
        "accounts %>%\n",
        "  ggplot(aes(x = date_opened, y = total)) +\n",
        "  geom_point()\n",
        "\n",
        "# Left join accounts to account_offices by id\n",
        "accounts %>%\n",
        "  left_join(account_offices, by = \"id\") %>%\n",
        "  # Convert totals from the Tokyo office to USD\n",
        "  mutate(total_usd = ifelse(office == \"Tokyo\", total / 104, total)) %>%\n",
        "  # Scatter plot of opening date vs total_usd\n",
        "  ggplot(aes(x = date_opened, y = total_usd)) +\n",
        "    geom_point()\n",
        "    \n"
      ],
      "metadata": {
        "id": "Nzdt8KCaRq6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a new column called theoretical_total that contains the sum of the amounts in each fund.\n",
        "Find the accounts where the total doesn't match the theoretical_total.\n",
        "\n",
        "# Find invalid totals\n",
        "accounts %>%\n",
        "  # theoretical_total: sum of the three funds\n",
        "  mutate(theoretical_total = fund_A + fund_B + fund_C) %>%\n",
        "  # Find accounts where total doesn't match theoretical_total\n",
        "  filter(theoretical_total != total)\n",
        "  "
      ],
      "metadata": {
        "id": "OLh2N_pNRq12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a new column called theoretical_age that contains the age of each account based on the date_opened.\n",
        "Find the accounts where the acct_age doesn't match the theoretical_age.\n",
        "\n",
        "\n",
        "# Find invalid acct_age\n",
        "accounts %>%\n",
        "  # theoretical_age: age of acct based on date_opened\n",
        "  mutate(theoretical_age = floor(as.numeric(date_opened %--% today(), \"years\"))) %>%\n",
        "  # Filter for rows where acct_age is different from theoretical_age\n",
        "  filter(acct_age != theoretical_age)"
      ],
      "metadata": {
        "id": "MIQxiuZ-Rqyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a new column called theoretical_age that contains the age of each account based on the date_opened.\n",
        "Find the accounts where the acct_age doesn't match the theoretical_age.\n",
        "\n",
        "# Find invalid acct_age\n",
        "accounts %>%\n",
        "  # theoretical_age: age of acct based on date_opened\n",
        "  mutate(theoretical_age = floor(as.numeric(date_opened %--% today(), \"years\"))) %>%\n",
        "  # Filter for rows where acct_age is different from theoretical_age\n",
        "  filter(acct_age != theoretical_age)"
      ],
      "metadata": {
        "id": "01uRDuA6IaHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Visualize the missing values in accounts by column using a function from the visdat package.\n",
        "\n",
        "# Visualize the missing values by column\n",
        "vis_miss(accounts)\n",
        "\n",
        "\n",
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Add a logical column to accounts called missing_inv that indicates whether each row is missing the inv_amount or not.\n",
        "Group by missing_inv.\n",
        "Calculate the mean age for each group of missing_inv.\n",
        "\n",
        "# Visualize the missing values by column\n",
        "vis_miss(accounts)\n",
        "\n",
        "accounts %>%\n",
        "  # missing_inv: Is inv_amount missing?\n",
        "  mutate(missing_inv = is.na(inv_amount)) %>%\n",
        "  # Group by missing_inv\n",
        "  group_by(missing_inv) %>%\n",
        "  # Calculate mean age for each missing_inv group\n",
        "  summarize(avg_age = mean(age))\n",
        "\n",
        "\n",
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Sort accounts by age.\n",
        "Visualize missing data by column.\n",
        "\n",
        "# Visualize the missing values by column\n",
        "vis_miss(accounts)\n",
        "\n",
        "accounts %>%\n",
        "  # missing_inv: Is inv_amount missing?\n",
        "  mutate(missing_inv = is.na(inv_amount)) %>%\n",
        "  # Group by missing_inv\n",
        "  group_by(missing_inv) %>%\n",
        "  # Calculate mean age for each missing_inv group\n",
        "  summarize(avg_age = mean(age))\n",
        "\n",
        "# Sort by age and visualize missing vals\n",
        "accounts %>%\n",
        "  arrange(age) %>%\n",
        "  vis_miss()"
      ],
      "metadata": {
        "id": "tVacBKznIZxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Filter accounts to remove rows with missing cust_ids and save as accounts_clean.\n",
        "\n",
        "\n",
        "# Create accounts_clean\n",
        "accounts_clean <- accounts %>%\n",
        "  # Filter to remove rows with missing cust_id\n",
        "  filter(!is.na(cust_id))\n",
        "\n",
        "accounts_clean\n",
        "\n",
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Create a new column called acct_amount_filled, which contains the values of acct_amount, except all NA values should be replaced with 5 times the amount in inv_amount.\n",
        "\n",
        "# Create accounts_clean\n",
        "accounts_clean <- accounts %>%\n",
        "  # Filter to remove rows with missing cust_id\n",
        "  filter(!is.na(cust_id)) %>%\n",
        "  # Add new col acct_amount_filled with replaced NAs\n",
        "  mutate(acct_amount_filled = ifelse(is.na(acct_amount), inv_amount * 5, acct_amount))\n",
        "\n",
        "accounts_clean\n",
        "\n",
        "\n",
        "Instructions 3/4\n",
        "25 XP\n",
        "3\n",
        "4\n",
        "Assert that there are no missing values in the cust_id column of accounts_clean.\n",
        "\n",
        "# Create accounts_clean\n",
        "accounts_clean <- accounts %>%\n",
        "  # Filter to remove rows with missing cust_id\n",
        "  filter(!is.na(cust_id)) %>%\n",
        "  # Add new col acct_amount_filled with replaced NAs\n",
        "  mutate(acct_amount_filled = ifelse(is.na(acct_amount), inv_amount * 5, acct_amount))\n",
        "\n",
        "# Assert that cust_id has no missing vals\n",
        "assert_all_are_not_na(accounts_clean$cust_id)\n",
        "\n",
        "Instructions 4/4\n",
        "25 XP\n",
        "4\n",
        "Assert that there are no missing values in the acct_amount_filled column of accounts_clean.\n",
        "\n",
        "# Create accounts_clean\n",
        "accounts_clean <- accounts %>%\n",
        "  # Filter to remove rows with missing cust_id\n",
        "  filter(!is.na(cust_id)) %>%\n",
        "  # Add new col acct_amount_filled with replaced NAs\n",
        "  mutate(acct_amount_filled = ifelse(is.na(acct_amount), inv_amount * 5, acct_amount))\n",
        "\n",
        "# Assert that cust_id has no missing vals\n",
        "assert_all_are_not_na(accounts_clean$cust_id)\n",
        "\n",
        "# Assert that acct_amount_filled has no missing vals\n",
        "assert_all_are_not_na(accounts_clean$acct_amount_filled)\n"
      ],
      "metadata": {
        "id": "jrAnkQpoIVE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4**"
      ],
      "metadata": {
        "id": "JmFv0ohZM82G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/4\n",
        "25 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "Calculate the Damerau-Levenshtein distance between \"las angelos\" and \"los angeles\".\n",
        "\n",
        "# Calculate Damerau-Levenshtein distance\n",
        "stringdist(\"las angelos\", \"los angeles\", method = \"dl\")\n",
        "\n",
        "Instructions 2/4\n",
        "25 XP\n",
        "2\n",
        "3\n",
        "4\n",
        "Calculate the Longest Common Substring (LCS) distance between \"las angelos\" and \"los angeles\".\n",
        "\n",
        "# Calculate LCS distance\n",
        "stringdist(\"las angelos\", \"los angeles\", method = \"lcs\")\n",
        "\n",
        "\n",
        "Instructions 3/4\n",
        "18 XP\n",
        "4\n",
        "Calculate the Jaccard distance between \"las angelos\" and \"los angeles\".\n",
        "# Calculate Jaccard distance\n",
        "stringdist(\"las angelos\", \"las angeles\", method = \"jaccard\")"
      ],
      "metadata": {
        "id": "90W0-8UuIUxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Count the number of each variation of city name in zagat.\n",
        "\n",
        "# Count the number of each city variation\n",
        "zagat %>%\n",
        "  count(city)\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Left join zagat and cities based on string distance using the city and city_actual columns.\n",
        "Select the name, city, and city_actual columns.\n",
        "\n",
        "\n",
        "# Count the number of each city variation\n",
        "zagat %>%\n",
        "  count(city)\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Left join zagat and cities based on string distance using the city and city_actual columns.\n",
        "Select the name, city, and city_actual columns.\n",
        "\n",
        "# Count the number of each city variation\n",
        "zagat %>%\n",
        "  count(city)\n",
        "\n",
        "# Join and look at results\n",
        "zagat %>%\n",
        "  # Left join based on stringdist using city and city_actual cols\n",
        "  stringdist_left_join(cities, by = c(\"city\" = \"city_actual\")) %>%\n",
        "  # Select the name, city, and city_actual cols\n",
        "  select(name, city, city_actual)"
      ],
      "metadata": {
        "id": "bMPzni8JRqsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "Load the reclin package.\n",
        "Generate all possible pairs of records between the zagat and fodors datasets.\n",
        "\n",
        "# Load reclin\n",
        "library(reclin)\n",
        "\n",
        "# Generate all possible pairs\n",
        "pair_blocking(zagat, fodors)\n",
        "\n",
        "\n",
        "Use pair blocking to generate only pairs that have matching values in the city column.\n",
        "\n",
        "# Load reclin\n",
        "library(reclin)\n",
        "\n",
        "# Generate pairs with same city\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\")\n",
        "\n"
      ],
      "metadata": {
        "id": "hUEG9CLwJDt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "Compare pairs by name using lcs() distance.\n",
        "\n",
        "# Generate pairs\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\") %>%\n",
        "  # Compare pairs by name using lcs()\n",
        "  compare_pairs(by = \"name\",\n",
        "                default_comparator = lcs())\n",
        "  \n",
        "Compare pairs by name, phone, and addr using jaro_winkler().\n",
        "\n",
        "# Generate pairs\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\") %>%\n",
        "  # Compare pairs by name, phone, addr\n",
        "  compare_pairs(by = c(\"name\", \"phone\", \"addr\"),\n",
        "                default_comparator = jaro_winkler())\n",
        "  \n"
      ],
      "metadata": {
        "id": "wCuplXoRRqpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Score the pairs of records probabilistically.\n",
        "\n",
        "# Create pairs\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\") %>%\n",
        "  # Compare pairs\n",
        "  compare_pairs(by = \"name\", default_comparator = jaro_winkler()) %>%\n",
        "  # Score pairs\n",
        "  score_problink()\n",
        "\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Select the pairs that are considered matches.\n",
        "\n",
        "# Create pairs\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\") %>%\n",
        "  # Compare pairs\n",
        "  compare_pairs(by = \"name\", default_comparator = jaro_winkler()) %>%\n",
        "  # Score pairs\n",
        "  score_problink() %>%\n",
        "  # Select pairs\n",
        "  select_n_to_m()\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Link the two data frames together.\n",
        "\n",
        "# Create pairs\n",
        "pair_blocking(zagat, fodors, blocking_var = \"city\") %>%\n",
        "  # Compare pairs\n",
        "  compare_pairs(by = \"name\", default_comparator = jaro_winkler()) %>%\n",
        "  # Score pairs\n",
        "  score_problink() %>%\n",
        "  # Select pairs\n",
        "  select_n_to_m() %>%\n",
        "  # Link data \n",
        "  link"
      ],
      "metadata": {
        "id": "bJTmwXP4RqlF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}