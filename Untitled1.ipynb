{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORSJ40aGjrtkim2Rds3zQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk0P2TK1xa5R"
      },
      "outputs": [],
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the import statement to load the numpy package.\n",
        "Use numpy's array class to define arr.\n",
        "Use arr's sort method to sort the numpy array.\n",
        "\n",
        "\n",
        "# import the numpy package\n",
        "import numpy as np\n",
        "\n",
        "# create an array class object\n",
        "arr = np.array([8, 6, 7, 5, 3, 0, 9])\n",
        "\n",
        "# use the sort method\n",
        "arr.sort()\n",
        "\n",
        "# print the sorted array\n",
        "print(arr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "View the documentation of the Counter.most_common method using the help() function. Note, you need to run the import statement before completing this step.\n",
        "\n",
        "\n",
        "# Load the Counter function into our environment\n",
        "from collections import Counter\n",
        "\n",
        "# View the documentation for Counter.most_common\n",
        "help(Counter.most_common)\n",
        "\n",
        "\n",
        "Correctly call Counter.most_common() by reading its documentation.\n",
        "Print the results stored in top_5_words.\n",
        "\n",
        "\n",
        "# Load the Counter function into our environment\n",
        "from collections import Counter\n",
        "\n",
        "# View the documentation for Counter.most_common\n",
        "help(Counter.most_common)\n",
        "\n",
        "# Use Counter to find the top 5 most common words\n",
        "top_5_words = Counter(words).most_common(5)\n",
        "\n",
        "# Display the top 5 most common words\n",
        "print(top_5_words)\n"
      ],
      "metadata": {
        "id": "-wSRTUOuufcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the pycodestyle package.\n",
        "Create an instance of StyleGuide named style_checker.\n",
        "There are two files that we'll be checking; they're named 'nay_pep8.py' and 'yay_pep8.py'. Pass a list containing these file names to our style_checker's check_files method.\n",
        "print() the results of our style check to the console. Make sure to read the output!\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import pycodestyle\n",
        "\n",
        "# Create a StyleGuide instance\n",
        "style_checker = pycodestyle.StyleGuide()\n",
        "\n",
        "# Run PEP 8 check on multiple files\n",
        "result = style_checker.check_files(['nay_pep8.py', 'yay_pep8.py'])\n",
        "\n",
        "# Print result of PEP 8 style check\n",
        "print(result.messages)\n",
        "\n"
      ],
      "metadata": {
        "id": "k9gzpBiHXogy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Leverage the output of pycodestyle to edit the code to be compliant with PEP 8.\n",
        "\n",
        "# Assign data to x\n",
        "x = [8, 3, 4]\n",
        "\n",
        "# Print the data\n",
        "print(x)"
      ],
      "metadata": {
        "id": "onqaZx91XodO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Leverage the output of pycodestyle to edit the code's comments to be compliant with PEP 8.\n",
        "\n",
        "def print_phrase(phrase, polite=True, shout=False):\n",
        "    if polite:# It's generally polite to say please\n",
        "        phrase = 'Please ' + phrase\n",
        "\n",
        "    if shout:  #All caps looks like a written shout\n",
        "        phrase = phrase.upper() + '!!'\n",
        "\n",
        "    print(phrase)\n",
        "\n",
        "\n",
        "#Politely ask for help\n",
        "print_phrase('help me', polite=True)\n",
        " # Shout about a discovery\n",
        "print_phrase('eureka', shout=True)"
      ],
      "metadata": {
        "id": "xcADHusbufZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "The possible package names to import are the following: text_analyzer, textAnalyzer, TextAnalyzer, & __text_analyzer__.\n",
        "import the package from the list above that follows the PEP 8 naming conventions.\n",
        "\n",
        "\n",
        "# Import local packages\n",
        "import package\n",
        "import py_package\n",
        "\n",
        "# View the help for each package\n",
        "help(package)\n",
        "help(py_package)"
      ],
      "metadata": {
        "id": "rWmDGQmmxu6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "1 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Define top_items using plot_counter's inputs.\n",
        "\n",
        "\n",
        "# Import needed functionality\n",
        "from collections import Counter\n",
        "\n",
        "def plot_counter(counter, n_most_common=5):\n",
        "  # Subset the n_most_common items from the input counter\n",
        "  top_items = counter.most_common(n_most_common)\n",
        "  # Plot `top_items`\n",
        "  plot_counter_most_common(top_items)\n",
        "\n",
        "\n",
        "\n",
        "Return the correct output from sum_counters.\n",
        "\n",
        "# Import needed functionality\n",
        "from collections import Counter\n",
        "\n",
        "def sum_counters(counters):\n",
        "  # Sum the inputted counters\n",
        "  return sum(counters, Counter())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QQmGPUhSxu2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import your text_analyzer at the top of the script.\n",
        "Use the sum_counters() function from text_analyzer to aggregate all the Counters in word_counts.\n",
        "Use the plot_counter() function from text_analyzer to visualize the tweet's most used words while tweeting.\n",
        "\n",
        "# Import local package\n",
        "import text_analyzer\n",
        "\n",
        "# Sum word_counts using sum_counters from text_analyzer\n",
        "word_count_totals = text_analyzer.sum_counters(word_counts)\n",
        "\n",
        "# Plot word_count_totals using plot_counter from text_analyzer\n",
        "text_analyzer.plot_counter(word_count_totals)"
      ],
      "metadata": {
        "id": "TZVBac2Oxuzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Write the requirement for matplotlib with at least version 3.0.0 or above.\n",
        "Write the requirement for numpy version 1.15.4 exactly.\n",
        "Write the requirement for pandas with at most version 0.22.0.\n",
        "Write a non-version specific requirement for pycodestyle\n",
        "\n",
        "\n",
        "requirements = \"\"\"\n",
        "matplotlib>=3.0.0\n",
        "numpy==1.15.4\n",
        "pandas<=0.22.0\n",
        "pycodestyle\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "V_6yBHz0xulQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import the needed function, setup, from the setuptools package.\n",
        "Complete the name & packages arguments; keep in mind your package is located in a directory named text_analyzer.\n",
        "List yourself as the author.\n",
        "\n",
        "\n",
        "# Import needed function from setuptools\n",
        "from setuptools import setup\n",
        "\n",
        "# Create proper setup to be used by pip\n",
        "setup(name='text_analyzer',\n",
        "      version='0.0.1',\n",
        "      description='Perform and visualize a text anaylsis.',\n",
        "      author='username',\n",
        "      packages=['text_analyzer'])"
      ],
      "metadata": {
        "id": "wxdgdkNRmZ3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import the needed function, setup, from the setuptools package.\n",
        "Complete the name & packages arguments; keep in mind your package is located in a directory named text_analyzer.\n",
        "List yourself as the author.\n",
        "\n",
        "# Import needed function from setuptools\n",
        "from setuptools import setup\n",
        "\n",
        "# Create proper setup to be used by pip\n",
        "setup(name='text_analyzer',\n",
        "      version='0.0.1',\n",
        "      description='Perform and visualize a text anaylsis.',\n",
        "      author='username',\n",
        "      packages=['text_analyzer'])\n"
      ],
      "metadata": {
        "id": "tSC2Wx25m1XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import the needed function, setup, from the setuptools package.\n",
        "List yourself as the author.\n",
        "Specify your install_requires to require matplotlib version 3.0.0 or above.\n",
        "\n",
        "\n",
        "# Import needed function from setuptools\n",
        "from setuptools import setup\n",
        "\n",
        "# Create proper setup to be used by pip\n",
        "setup(name='text_analyzer',\n",
        "      version='0.0.1',\n",
        "      description='Perform and visualize a text anaylsis.',\n",
        "      author='username',\n",
        "      packages=['text_analyzer'],\n",
        "      install_requires=['matplotlib>=3.0.0'])"
      ],
      "metadata": {
        "id": "rOb71rIalwek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "You are working in document.py.\n",
        "Finish the def statement that will create a new Document instance when a user calls Document().\n",
        "Use your knowledge of PEP 8 conventions to complete the definition of the newly named class method.\n",
        "\n",
        "# Define Document class\n",
        "class Document:\n",
        "    \"\"\"A class for text analysis\n",
        "\n",
        "    :param text: string of text to be analyzed\n",
        "    :ivar text: string of text to be analyzed; set by `text` parameter\n",
        "    \"\"\"\n",
        "    # Method to create a new instance of MyClass\n",
        "    def __init__(self, text):\n",
        "        # Store text parameter to the text attribute\n",
        "        self.text = text\n",
        "\n"
      ],
      "metadata": {
        "id": "cRfBv4m7n2Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import your text_analyzer package.\n",
        "Create an instance of Document with the datacamp_tweet variable that's been loaded into your session.\n",
        "Print the contents of the text attribute of your newly created Document instance.\n",
        "\n",
        "# Import custom text_analyzer package\n",
        "import text_analyzer\n",
        "\n",
        "# Create an instance of Document with datacamp_tweet\n",
        "my_document = text_analyzer.Document(text=datacamp_tweet)\n",
        "\n",
        "# Print the text attribute of the Document instance\n",
        "print(my_document.text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n4qyElZYnlQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Counter from collections has been loaded into your environment, as well as the function tokenize().\n",
        "Add a method named count_words as a non-public method.\n",
        "Give your non-public method the functionality to count the contents tokens attribute using Counter().\n",
        "Utilize your new function in the __init__ method.\n",
        "\n",
        "class Document:\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "    # pre tokenize the document with non-public tokenize method\n",
        "    self.tokens = self._tokenize()\n",
        "    # pre tokenize the document with non-public count_words\n",
        "    self.word_counts = self._count_words()\n",
        "\n",
        "  def _tokenize(self):\n",
        "    return tokenize(self.text)\n",
        "\n",
        "  # non-public method to tally document's word counts with Counter\n",
        "  def _count_words(self):\n",
        "    return Counter(self.tokens)\n"
      ],
      "metadata": {
        "id": "JdXOZeAXj49c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a new Document instance from the datacamp_tweets data set loaded into your environment. The datacamp_tweets object is a single string containing hundreds of tweets written by DataCamp & DataCamp users.\n",
        "Print the first 5 tokens from datacamp_doc.\n",
        "Print the top 5 most common words that were calculated by the non-public _count_words() method automatically in the Document.__init__ method.\n",
        "\n",
        "# create a new document instance from datacamp_tweets\n",
        "datacamp_doc = Document(datacamp_tweets)\n",
        "\n",
        "# print the first 5 tokens from datacamp_doc\n",
        "print(datacamp_doc.tokens[:5])\n",
        "\n",
        "# print the top 5 most used words in datacamp_doc\n",
        "print(datacamp_doc.word_counts.most_common(5))\n",
        "\n"
      ],
      "metadata": {
        "id": "47oFEyY7eIm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Document has been preloaded in the session.\n",
        "Complete the class statement to create a SocialMedia class that inherits from Document.\n",
        "Define SocialMedia's __init__() method that initializes a Document.\n",
        "\n",
        "\n",
        "# Define a SocialMedia class that is a child of the `Document class`\n",
        "class SocialMedia(Document):\n",
        "    def __init__(self, text):\n",
        "        Document.__init__(self, text)"
      ],
      "metadata": {
        "id": "rYcphTBfeIVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "The function filter_word_counts() has been loaded in your session. Use help() to see its proper usage.\n",
        "Finish the _count_hashtags method using filter_word_counts() so that only words_counts starting with # remain.\n",
        "\n",
        "# Define a SocialMedia class that is a child of the `Document class`\n",
        "class SocialMedia(Document):\n",
        "    def __init__(self, text):\n",
        "        Document.__init__(self, text)\n",
        "        self.hashtag_counts = self._count_hashtags()\n",
        "\n",
        "    def _count_hashtags(self):\n",
        "        # Filter attribute so only words starting with '#' remain\n",
        "        return filter_word_counts(self.word_counts, first_char='#')\n",
        "\n"
      ],
      "metadata": {
        "id": "hSshgqjSq9DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Fill in the first line ofSocialMedia's __init__ method using the parent class to properly utilize inheritance.\n",
        "Properly call the _count_mentions method in __init__ to add a new feature to SocialMedia.\n",
        "\n",
        "# Define a SocialMedia class that is a child of the `Document class`\n",
        "class SocialMedia(Document):\n",
        "    def __init__(self, text):\n",
        "        Document.__init__(self, text)\n",
        "        self.hashtag_counts = self._count_hashtags()\n",
        "        self.mention_counts = self._count_mentions()\n",
        "\n",
        "    def _count_hashtags(self):\n",
        "        # Filter attribute so only words starting with '#' remain\n",
        "        return filter_word_counts(self.word_counts, first_char='#')\n",
        "\n",
        "    def _count_mentions(self):\n",
        "        # Filter attribute so only words starting with '@' remain\n",
        "        return filter_word_counts(self.word_counts, first_char='@')\n"
      ],
      "metadata": {
        "id": "KXTxcCZcsa_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 2/2\n",
        "0 XP\n",
        "2\n",
        "Fill in the first line ofSocialMedia's __init__ method using the parent class to properly utilize inheritance.\n",
        "Properly call the _count_mentions method in __init__ to add a new feature to SocialMedia.\n",
        "\n",
        "# Define a SocialMedia class that is a child of the `Document class`\n",
        "class SocialMedia(Document):\n",
        "    def __init__(self, text):\n",
        "        Document.__init__(self, text)\n",
        "        self.hashtag_counts = self._count_hashtags()\n",
        "        self.mention_counts = self._count_mentions()\n",
        "\n",
        "    def _count_hashtags(self):\n",
        "        # Filter attribute so only words starting with '#' remain\n",
        "        return filter_word_counts(self.word_counts, first_char='#')\n",
        "\n",
        "    def _count_mentions(self):\n",
        "        # Filter attribute so only words starting with '@' remain\n",
        "        return filter_word_counts(self.word_counts, first_char='@')\n",
        "\n"
      ],
      "metadata": {
        "id": "Mtci6lPDsaaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import your text_analyzer custom package.\n",
        "Define dc_tweets as an instance of SocialMedia with the preloaded datacamp_tweets object as the text.\n",
        "print the 5 most_common mentioned users in the data using the appropriate dc_tweets attribute.\n",
        "Use text_analyzer's plot_counter() method to plot the most used hashtags in the data using the appropriate dc_tweets attribute.\n",
        "\n",
        "\n",
        "# Import custom text_analyzer package\n",
        "import text_analyzer\n",
        "\n",
        "# Create a SocialMedia instance with datacamp_tweets\n",
        "dc_tweets = text_analyzer.SocialMedia(text=datacamp_tweets)\n",
        "\n",
        "# Print the top five most most mentioned users\n",
        "print(dc_tweets.mention_counts.most_common(5))\n",
        "\n",
        "# Plot the most used hashtags\n",
        "text_analyzer.plot_counter(dc_tweets.hashtag_counts)\n"
      ],
      "metadata": {
        "id": "xUgHZ0Dpsouv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "import the text_analyzer package.\n",
        "Define my_doc as an instance of Document with the text stored in datacamp_tweets. datacamp_tweets has been pre-loaded in your environment.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of document\n",
        "my_doc = text_analyzer.Document(datacamp_tweets)\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Run help() on the plot method you discovered with dir() to see how to properly use the functionality.\n",
        "Plot my_doc's word counts using the new plot method.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of document\n",
        "my_doc = text_analyzer.Document(datacamp_tweets)\n",
        "\n",
        "# Run help on my_doc's plot method\n",
        "help(my_doc.plot_counts)\n",
        "\n",
        "# Plot the word_counts of my_doc\n",
        "my_doc.plot_counts()\n"
      ],
      "metadata": {
        "id": "funtBy1WtuHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Run help() on the plot method you discovered with dir() to see how to properly use the functionality.\n",
        "Plot my_doc's word counts using the new plot method.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of document\n",
        "my_doc = text_analyzer.Document(datacamp_tweets)\n",
        "\n",
        "# Run help on my_doc's plot method\n",
        "help(my_doc.plot_counts)\n",
        "\n",
        "# Plot the word_counts of my_doc\n",
        "my_doc.plot_counts()\n"
      ],
      "metadata": {
        "id": "FPlq7Qvmttei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the class statement so that Tweets inherits from SocialMedia. SocialMedia has already been loaded in your environment.\n",
        "Use super() to call the __init__ method of the parent class.\n",
        "Define retweet_text. Use help() to complete the call to filter_lines with the correct parameter name. filter_lines has already been loaded in your environment.\n",
        "return retweet_text from _process_retweets as an instance of SocialMedia.\n",
        "\n",
        "\n",
        "# Define a Tweet class that inherits from SocialMedia\n",
        "class Tweets(SocialMedia):\n",
        "    def __init__(self, text):\n",
        "        # Call parent's __init__ with super()\n",
        "        super().__init__(text)\n",
        "        # Define retweets attribute with non-public method\n",
        "        self.retweets = self._process_retweets()\n",
        "\n",
        "    def _process_retweets(self):\n",
        "        # Filter tweet text to only include retweets\n",
        "        retweet_text = filter_lines(self.text, first_chars='RT')\n",
        "        # Return retweet_text as a SocialMedia object\n",
        "        return SocialMedia(retweet_text)\n"
      ],
      "metadata": {
        "id": "SFVPeFjWttbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "import your text_analyzer package.\n",
        "Define my_tweets as an instance of Tweets using the datacamp_tweets data that has been pre-loaded into your environment.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of Tweets\n",
        "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
        "\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Use the plot_counts() method to plot the top 'hashtag_counts'.\n",
        "Make sure to check the documentation for my_tweets.plot_counts.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of Tweets\n",
        "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
        "\n",
        "# Plot the most used hashtags in the tweets\n",
        "my_tweets.plot_counts('hashtag_counts')\n",
        "\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Use the plot_counts() method of the retweets attribute to plot the most used hashtags in the retweets subset of the data.\n",
        "\n",
        "\n",
        "# Import needed package\n",
        "import text_analyzer\n",
        "\n",
        "# Create instance of Tweets\n",
        "my_tweets = text_analyzer.Tweets(datacamp_tweets)\n",
        "\n",
        "# Plot the most used hashtags in the retweets\n",
        "my_tweets.retweets.plot_counts('hashtag_counts')"
      ],
      "metadata": {
        "id": "0utfyeQYFJro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print the text variable that has been pre-loaded into your environment.\n",
        "print the result of calling the function with more useful commenting on text.\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_0(text):\n",
        "    # match and extract dollar amounts from the text\n",
        "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
        "\n",
        "def extract_1(text):\n",
        "    # return all matches to regex pattern\n",
        "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
        "\n",
        "# Print the text\n",
        "print(text)\n",
        "\n",
        "# Print the results of the function with better commenting\n",
        "print(extract_0(text))\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_0(text):\n",
        "    # match and extract dollar amounts from the text\n",
        "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
        "\n",
        "def extract_1(text):\n",
        "    # return all matches to regex pattern\n",
        "    return re.findall(r'\\$\\d+\\.\\d\\d', text)\n",
        "\n",
        "# Print the text\n",
        "print(text)\n",
        "\n",
        "# Print the results of the function with better commenting\n",
        "print(extract_0(text))\n",
        "\n"
      ],
      "metadata": {
        "id": "qIaQdVdGFgYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Run help() on each of the 4 functions to view their docstrings.\n",
        "\n",
        "# Run the help on all 4 functions\n",
        "help(goldilocks)\n",
        "help(rapunzel)\n",
        "help(mary)\n",
        "help(sleeping_beauty)\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "0 XP\n",
        "Define result using the function that has the most complete docstring; only 1 of the 4 contains all the sections we covered. Call the function without any parameters.\n",
        "print the result of the most well documented function.\n",
        "\n",
        "\n",
        "# Run the help on all 4 functions\n",
        "help(goldilocks)\n",
        "help(rapunzel)\n",
        "help(mary)\n",
        "help(sleeping_beauty)\n",
        "\n",
        "# Execute the function with most complete docstring\n",
        "result = rapunzel()\n",
        "\n",
        "# Print the result\n",
        "print(result)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7VcsCpA2MOKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the portions of the docstring that document the parameters.\n",
        "Complete the portion of the docstring describing the return value.\n",
        "Complete the example function usage in the docstring.\n",
        "\n",
        "# Complete the function's docstring\n",
        "def tokenize(text, regex=r'[a-zA-z]+'):\n",
        "  \"\"\"Split text into tokens using a regular expression\n",
        "\n",
        "  :param text: text to be tokenized\n",
        "  :param regex: regular expression used to match tokens using re.findall\n",
        "  :return: a list of resulting tokens\n",
        "\n",
        "  >>> tokenize('the rain in spain')\n",
        "  ['the', 'rain', 'in', 'spain']\n",
        "  \"\"\"\n",
        "  return re.findall(regex, text, flags=re.IGNORECASE)\n",
        "\n",
        "# Print the docstring\n",
        "help(tokenize)\n"
      ],
      "metadata": {
        "id": "QOH7rVuGMOHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "The math module has been pre-loaded into your environment to be able to use its sqrt function.\n",
        "Give function the best possible name from the following options: do_stuff, hypotenuse_length, square_root_of_leg_a_squared_plus_leg_b_squared, pythagorean_theorem.\n",
        "Complete the docstring's example with the function's name.\n",
        "print the result of using the newly named function to find the length of the hypotenuse for a right triangle with legs of length 6 & 8.\n",
        "\n",
        "\n",
        "def hypotenuse_length(leg_a, leg_b):\n",
        "    \"\"\"Find the length of a right triangle's hypotenuse\n",
        "\n",
        "    :param leg_a: length of one leg of triangle\n",
        "    :param leg_b: length of other leg of triangle\n",
        "    :return: length of hypotenuse\n",
        "\n",
        "    >>> hypotenuse_length(3, 4)\n",
        "    5\n",
        "    \"\"\"\n",
        "    return math.sqrt(leg_a**2 + leg_b**2)\n",
        "\n",
        "\n",
        "# Print the length of the hypotenuse with legs 6 & 8\n",
        "print(hypotenuse_length(6, 8))"
      ],
      "metadata": {
        "id": "UNSP2szCID4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Choose the best variable name to hold the sample of pupil diameter measurements in millimeters from the following choices: d, diameter, pupil_diameter, or pupil_diameter_in_millimeters.\n",
        "Take the mean of the measurements and assign it to a variable. Choose the best variable name to hold this mean from the following options: m, mean, mean_diameter, or mean_pupil_diameter_in_millimeters.\n",
        "Print the resulting average pupil diameter.\n",
        "\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "# Sample measurements of pupil diameter in mm\n",
        "pupil_diameter = [3.3, 6.8, 7.0, 5.4, 2.7]\n",
        "\n",
        "# Average pupil diameter from sample\n",
        "mean_diameter = mean(pupil_diameter)\n",
        "\n",
        "print(mean_diameter)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gUNSQgN1Qlrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Move the logic for calculating the perimeter into the polygon_perimeter function.\n",
        "Complete the definition of the polygon_apothem function, by moving the logic seen in the context. The math module has already been imported for you.\n",
        "Utilize the new unit functions to complete the definition of polygon_area.\n",
        "Use the more unitized polygon_area to calculate the area of a regular hexagon with legs of size 10.\n",
        "\n",
        "def polygon_perimeter(n_sides, side_len):\n",
        "    return n_sides * side_len\n",
        "\n",
        "def polygon_apothem(n_sides, side_len):\n",
        "    denominator = 2 * math.tan(math.pi / n_sides)\n",
        "    return side_len / denominator\n",
        "\n",
        "def polygon_area(n_sides, side_len):\n",
        "    perimeter = polygon_perimeter(n_sides, side_len)\n",
        "    apothem = polygon_apothem(n_sides, side_len)\n",
        "\n",
        "    return perimeter * apothem / 2\n",
        "\n",
        "# Print the area of a hexagon with legs of size 10\n",
        "print(polygon_area(n_sides=6, side_len=10))\n",
        "\n"
      ],
      "metadata": {
        "id": "3sbNLFi1Q7jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the input code of the example in the docstring for sum_counters.\n",
        "Complete the docstring example by filling in the expected output.\n",
        "Run the testmod function from doctest to test your function's example code.\n",
        "\n",
        "\n",
        "def sum_counters(counters):\n",
        "    \"\"\"Aggregate collections.Counter objects by summing counts\n",
        "\n",
        "    :param counters: list/tuple of counters to sum\n",
        "    :return: aggregated counters with counts summed\n",
        "\n",
        "    >>> d1 = text_analyzer.Document('1 2 fizz 4 buzz fizz 7 8')\n",
        "    >>> d2 = text_analyzer.Document('fizz buzz 11 fizz 13 14')\n",
        "    >>> sum_counters([d1.word_counts, d2.word_counts])\n",
        "    Counter({'fizz': 4, 'buzz': 2})\n",
        "    \"\"\"\n",
        "    return sum(counters, Counter())\n",
        "\n",
        "doctest.testmod()\n"
      ],
      "metadata": {
        "id": "pve-3RBEkHjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "import the SocialMedia class.\n",
        "Complete the name of the test function so it is run by pytest.\n",
        "Use the appropriate keyword to test that the hashtag_counts are as expected.\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from text_analyzer import SocialMedia\n",
        "\n",
        "# Create an instance of SocialMedia for testing\n",
        "test_post = 'learning #python & #rstats is awesome! thanks @datacamp!'\n",
        "sm_post = SocialMedia(test_post)\n",
        "\n",
        "# Test hashtag counts are created properly\n",
        "def test_social_media_hashtags():\n",
        "    expected_hashtag_counts = Counter({'#python': 1, '#rstats': 1})\n",
        "    assert sm_post.hashtag_counts == expected_hashtag_counts"
      ],
      "metadata": {
        "id": "vcv0jQT6kHKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Instructions\n",
        "100 XP\n",
        "import the Document class from the text_analyzer package for use in the class definition.\n",
        "Complete the line of the docstring dealing with the parameters of the __init__ method.\n",
        "Complete the docstring by filling out the documentation for the attributes or 'instance variables' of the SocialMedia class.\n",
        "\n",
        "\n",
        "from text_analyzer import Document\n",
        "\n",
        "class SocialMedia(Document):\n",
        "    \"\"\"Analyze text data from social media\n",
        "\n",
        "    :param text: social media text to analyze\n",
        "\n",
        "    :ivar hashtag_counts: Counter object containing counts of hashtags used in text\n",
        "    :ivar mention_counts: Counter object containing counts of @mentions used in text\n",
        "    \"\"\"\n",
        "    def __init__(self, text):\n",
        "        Document.__init__(self, text)\n",
        "        self.hashtag_counts = self._count_hashtags()\n",
        "        self.mention_counts = self._count_mentions()\n",
        "\n"
      ],
      "metadata": {
        "id": "FZMhmZiCQloQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRaZHMWnQllk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}