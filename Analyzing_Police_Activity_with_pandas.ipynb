{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Analyzing Police Activity with pandas.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPa/WeD6xS6CRi15UPQQfbd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Analyzing_Police_Activity_with_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9xsqWIeheQ6"
      },
      "source": [
        "Analyzing Police Activity with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc-xDWxVjNjP"
      },
      "source": [
        "1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DML3zYIZhbJp"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import pandas using the alias pd.\n",
        "Read the file police.csv into a DataFrame named ri.\n",
        "Examine the first 5 rows of the DataFrame (known as the \"head\").\n",
        "Count the number of missing values in each column: Use .isnull() to check which DataFrame elements are missing, and then take the .sum() to count the number of True values in each column.\n",
        "\n",
        "\n",
        "# Import the pandas library as pd\n",
        "import pandas as pd\n",
        "\n",
        "# Read 'police.csv' into a DataFrame named ri\n",
        "ri = pd.read_csv('police.csv')\n",
        "\n",
        "# Examine the head of the DataFrame\n",
        "print(ri.head())\n",
        "\n",
        "# Count the number of missing values in each column\n",
        "print(ri.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfbf7ic6kLtb"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Examine the DataFrame's .shape to find out the number of rows and columns.\n",
        "Drop both the county_name and state columns by passing the column names to the .drop() method as a list of strings.\n",
        "Examine the .shape again to verify that there are now two fewer columns.\n",
        "\n",
        "# Examine the shape of the DataFrame\n",
        "print(ri.shape)\n",
        "\n",
        "# Drop the 'county_name' and 'state' columns\n",
        "ri.drop(['county_name', 'state'], axis='columns', inplace=True)\n",
        "\n",
        "# Examine the shape of the DataFrame (again)\n",
        "print(ri.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLV54KOVkyxi"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Count the number of missing values in each column.\n",
        "Drop all rows that are missing driver_gender by passing the column name to the subset parameter of .dropna().\n",
        "Count the number of missing values in each column again, to verify that none of the remaining rows are missing driver_gender.\n",
        "Examine the DataFrame's .shape to see how many rows and columns remain.\n",
        "\n",
        "\n",
        "# Examine the shape of the DataFrame\n",
        "print(ri.shape)\n",
        "\n",
        "# Drop the 'county_name' and 'state' columns\n",
        "ri.drop(['county_name', 'state'], axis='columns', inplace=True)\n",
        "\n",
        "# Examine the shape of the DataFrame (again)\n",
        "print(ri.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyFRzj0_l5Zd"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Count the number of missing values in each column.\n",
        "Drop all rows that are missing driver_gender by passing the column name to the subset parameter of .dropna().\n",
        "Count the number of missing values in each column again, to verify that none of the remaining rows are missing driver_gender.\n",
        "Examine the DataFrame's .shape to see how many rows and columns remain.\n",
        "\n",
        "# Count the number of missing values in each column\n",
        "print(ri.isnull().sum())\n",
        "\n",
        "# Drop all rows that are missing 'driver_gender'\n",
        "ri.dropna(subset=['driver_gender'], inplace=True)\n",
        "\n",
        "# Count the number of missing values in each column (again)\n",
        "print(ri.isnull().sum())\n",
        "\n",
        "# Examine the shape of the DataFrame\n",
        "print(ri.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSMm423zCJ4n"
      },
      "source": [
        "Finding an incorrect data type\n",
        "The dtypes attribute of the ri DataFrame has been printed for you. Your task is to explore the ri DataFrame in the IPython Shell to determine which column's data type should be changed.\n",
        "\n",
        "r: is_arrested should have a data type of bool"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhmL9uV8CWHh"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Examine the head of the is_arrested column to verify that it contains True and False values and to check the column's data type.\n",
        "Use the .astype() method to convert is_arrested to a bool column.\n",
        "Check the new data type of is_arrested to confirm that it is now a bool column.\n",
        "\n",
        "# Examine the head of the 'is_arrested' column\n",
        "print(ri.is_arrested.head())\n",
        "\n",
        "# Change the data type of 'is_arrested' to 'bool'\n",
        "ri['is_arrested'] = ri.is_arrested.astype('bool')\n",
        "\n",
        "# Check the data type of 'is_arrested' \n",
        "print(ri.is_arrested.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrsz7Pz-MFNO"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Use a string method to concatenate stop_date and stop_time (separated by a space), and store the result in combined.\n",
        "Convert combined to datetime format, and store the result in a new column named stop_datetime.\n",
        "Examine the DataFrame .dtypes to confirm that stop_datetime is a datetime column.\n",
        "\n",
        "# Concatenate 'stop_date' and 'stop_time' (separated by a space)\n",
        "combined = ri.stop_date.str.cat(ri.stop_time, sep=' ')\n",
        "\n",
        "# Convert 'combined' to datetime format\n",
        "ri['stop_datetime'] = pd.to_datetime(combined)\n",
        "\n",
        "# Examine the data types of the DataFrame\n",
        "print(ri.dtypes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqyy7NImP9Eg"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Set stop_datetime as the DataFrame index.\n",
        "Examine the index to verify that it is a DatetimeIndex.\n",
        "Examine the DataFrame columns to confirm that stop_datetime is no longer one of the columns.\n",
        "\n",
        "# Set 'stop_datetime' as the index\n",
        "ri.set_index('stop_datetime', inplace=True)\n",
        "\n",
        "# Examine the index\n",
        "print(ri.index)\n",
        "\n",
        "# Examine the columns\n",
        "print(ri.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QOVJKJ8QzqO"
      },
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W300EkwhQhMs"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Count the unique values in the violation column of the ri DataFrame, to see what violations are being committed by all drivers.\n",
        "Express the violation counts as proportions of the total.\n",
        "\n",
        "# Count the unique values in 'violation'\n",
        "print(ri.violation.value_counts())\n",
        "\n",
        "# Express the counts as proportions\n",
        "print(ri.violation.value_counts(normalize=True))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzPo6dDdia6Z"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a DataFrame, female, that only contains rows in which driver_gender is 'F'.\n",
        "Create a DataFrame, male, that only contains rows in which driver_gender is 'M'.\n",
        "Count the violations committed by female drivers and express them as proportions.\n",
        "Count the violations committed by male drivers and express them as proportions.\n",
        "\n",
        "# Create a DataFrame of female drivers\n",
        "female = ri[ri.driver_gender == 'F']\n",
        "\n",
        "# Create a DataFrame of male drivers\n",
        "male = ri[ri.driver_gender == 'M']\n",
        "\n",
        "# Compute the violations by female drivers (as proportions)\n",
        "print(female.violation.value_counts(normalize = True))\n",
        "\n",
        "# Compute the violations by male drivers (as proportions)\n",
        "print(male.violation.value_counts(normalize = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CucwU669yQy5"
      },
      "source": [
        "Filtering by multiple conditions\n",
        "Which one of these commands would filter the ri DataFrame to only include female drivers who were stopped for a speeding violation?\n",
        "\n",
        "R: ri[(ri.driver_gender == 'F') & (ri.violation == 'Speeding')]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJvmvszgzNrI"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a DataFrame, female_and_speeding, that only includes female drivers who were stopped for speeding.\n",
        "Create a DataFrame, male_and_speeding, that only includes male drivers who were stopped for speeding.\n",
        "Count the stop outcomes for the female drivers and express them as proportions.\n",
        "Count the stop outcomes for the male drivers and express them as proportions.\n",
        "\n",
        "# Create a DataFrame of female drivers stopped for speeding\n",
        "female_and_speeding = ri[(ri.driver_gender == 'F') & (ri.violation == 'Speeding')]\n",
        "\n",
        "# Create a DataFrame of male drivers stopped for speeding\n",
        "male_and_speeding = ri[(ri.driver_gender == 'M') & (ri.violation == 'Speeding')]\n",
        "\n",
        "# Compute the stop outcomes for female drivers (as proportions)\n",
        "print(female_and_speeding.stop_outcome.value_counts(normalize=True))\n",
        "\n",
        "# Compute the stop outcomes for male drivers (as proportions)\n",
        "print(male_and_speeding.stop_outcome.value_counts(normalize=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3rhPw-z_j2q"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Check the data type of search_conducted to confirm that it's a Boolean Series.\n",
        "Calculate the search rate by counting the Series values and expressing them as proportions.\n",
        "Calculate the search rate by taking the mean of the Series. (It should match the proportion of True values calculated above.)\n",
        "\n",
        "\n",
        "# Check the data type of 'search_conducted'\n",
        "print(ri.search_conducted.dtype)\n",
        "\n",
        "# Calculate the search rate by counting the values\n",
        "print(ri.search_conducted.value_counts(normalize=True))\n",
        "\n",
        "# Calculate the search rate by taking the mean\n",
        "print(ri.search_conducted.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS42RsGGCnRu"
      },
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "2\n",
        "3\n",
        "Filter the DataFrame to only include female drivers, and then calculate the search rate by taking the mean of search_conducted.\n",
        "\n",
        "# Calculate the search rate for female drivers\n",
        "print(ri[ri.driver_gender == 'F'].search_conducted.mean())\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "2\n",
        "3\n",
        "Filter the DataFrame to only include male drivers, and then repeat the search rate calculation.\n",
        "\n",
        "# Calculate the search rate for male drivers\n",
        "print(ri[ri.driver_gender == 'M'].search_conducted.mean())\n",
        "\n",
        "Instructions 3/3\n",
        "30 XP\n",
        "3\n",
        "Group by driver gender to calculate the search rate for both groups simultaneously. (It should match the previous results.)\n",
        "\n",
        "\n",
        "# Calculate the search rate for both groups simultaneously\n",
        "print(ri.groupby('driver_gender').search_conducted.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjNCGBU7JAVj"
      },
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Use a .groupby() to calculate the search rate for each combination of gender and violation. Are males and females searched at about the same rate for each violation?\n",
        "\n",
        "# Calculate the search rate for each combination of gender and violation\n",
        "print(ri.groupby(['driver_gender', 'violation']).search_conducted.mean())\n",
        "\n",
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Reverse the ordering to group by violation before gender. The results may be easier to compare when presented this way.\n",
        "\n",
        "# Reverse the ordering to group by violation before gender\n",
        "print(ri.groupby(['violation', 'driver_gender']).search_conducted.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CziEGFWqKGl-"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Count the search_type values in the ri DataFrame to see how many times \"Protective Frisk\" was the only search type.\n",
        "Create a new column, frisk, that is True if search_type contains the string \"Protective Frisk\" and False otherwise.\n",
        "Check the data type of frisk to confirm that it's a Boolean Series.\n",
        "Take the sum of frisk to count the total number of frisks.\n",
        "\n",
        "# Count the 'search_type' values\n",
        "print(ri.search_type.value_counts())\n",
        "\n",
        "# Check if 'search_type' contains the string 'Protective Frisk'\n",
        "ri['frisk'] = ri.search_type.str.contains('Protective Frisk', na=False)\n",
        "\n",
        "# Check the data type of 'frisk'\n",
        "print(ri.frisk.dtype)\n",
        "\n",
        "# Take the sum of 'frisk'\n",
        "print(ri.frisk.sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XNwhK4lMxVX"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a DataFrame, searched, that only contains rows in which search_conducted is True.\n",
        "Take the mean of the frisk column to find out what percentage of searches included a frisk.\n",
        "Calculate the frisk rate for each gender using a .groupby().\n",
        "\n",
        "# Create a DataFrame of stops in which a search was conducted\n",
        "searched = ri[ri.search_conducted == True]\n",
        "\n",
        "# Calculate the overall frisk rate by taking the mean of 'frisk'\n",
        "print(searched.frisk.mean())\n",
        "\n",
        "# Calculate the frisk rate for each gender\n",
        "print(searched.groupby('driver_gender').frisk.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D43mVK_NM4HO"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Take the mean of the is_arrested column to calculate the overall arrest rate.\n",
        "Group by the hour attribute of the DataFrame index to calculate the hourly arrest rate.\n",
        "Save the hourly arrest rate Series as a new object, hourly_arrest_rate.\n",
        "\n",
        "# Calculate the overall arrest rate\n",
        "print(ri.is_arrested.mean())\n",
        "\n",
        "# Calculate the hourly arrest rate\n",
        "print(ri.groupby(ri.index.hour).is_arrested.mean())\n",
        "\n",
        "# Save the hourly arrest rate\n",
        "hourly_arrest_rate = ri.groupby(ri.index.hour).is_arrested.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGOEc_FqPZQE"
      },
      "source": [
        "\n",
        "3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaC95quaOkYm"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import matplotlib.pyplot using the alias plt.\n",
        "Create a line plot of hourly_arrest_rate using the .plot() method.\n",
        "Label the x-axis as 'Hour', label the y-axis as 'Arrest Rate', and title the plot 'Arrest Rate by Time of Day'.\n",
        "Display the plot using the .show() function.\n",
        "\n",
        "\n",
        "# Import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a line plot of 'hourly_arrest_rate'\n",
        "hourly_arrest_rate.plot()\n",
        "\n",
        "# Add the xlabel, ylabel, and title\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Arrest Rate')\n",
        "plt.title('Arrest Rate by Time of Day')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9uznD4XPCvj"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Calculate the annual rate of drug-related stops by resampling the drugs_related_stop column (on the 'A' frequency) and taking the mean.\n",
        "Save the annual drug rate Series as a new object, annual_drug_rate.\n",
        "Create a line plot of annual_drug_rate using the .plot() method.\n",
        "Display the plot using the .show() function.\n",
        "\n",
        "\n",
        "# Calculate the annual rate of drug-related stops\n",
        "print(ri.drugs_related_stop.resample('A').mean())\n",
        "\n",
        "# Save the annual rate of drug-related stops\n",
        "annual_drug_rate = ri.drugs_related_stop.resample('A').mean()\n",
        "\n",
        "# Create a line plot of 'annual_drug_rate'\n",
        "annual_drug_rate.plot()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkzYXCBUQ4us"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Calculate the annual search rate by resampling the search_conducted column, and save the result as annual_search_rate.\n",
        "Concatenate annual_drug_rate and annual_search_rate along the columns axis, and save the result as annual.\n",
        "Create subplots of the drug and search rates from the annual DataFrame.\n",
        "Display the subplots.\n",
        "\n",
        "# Calculate and save the annual search rate\n",
        "annual_search_rate = ri.search_conducted.resample('A').mean()\n",
        "\n",
        "# Concatenate 'annual_drug_rate' and 'annual_search_rate'\n",
        "annual = pd.concat([annual_drug_rate, annual_search_rate], axis='columns')\n",
        "\n",
        "# Create subplots from 'annual'\n",
        "annual.plot(subplots=True)\n",
        "\n",
        "# Display the subplots\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FwGWLYzR0LO"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a frequency table from the ri DataFrame's district and violation columns using the pd.crosstab() function.\n",
        "Save the frequency table as a new object, all_zones.\n",
        "Select rows 'Zone K1' through 'Zone K3' from all_zones using the .loc[] accessor.\n",
        "Save the smaller table as a new object, k_zones.\n",
        "\n",
        "# Create a frequency table of districts and violations\n",
        "print(pd.crosstab(ri.district, ri.violation))\n",
        "\n",
        "# Save the frequency table as 'all_zones'\n",
        "all_zones = pd.crosstab(ri.district, ri.violation)\n",
        "\n",
        "# Select rows 'Zone K1' through 'Zone K3'\n",
        "print(all_zones.loc['Zone K1':'Zone K3'])\n",
        "\n",
        "# Save the smaller table as 'k_zones'\n",
        "k_zones = all_zones.loc['Zone K1':'Zone K3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l24vFWDmU-6Q"
      },
      "source": [
        "Instructions 1/2\n",
        "50 XP\n",
        "1\n",
        "2\n",
        "Create a bar plot of k_zones.\n",
        "Display the plot and examine it. What do you notice about each of the zones?\n",
        "\n",
        "# Create a bar plot of 'k_zones'\n",
        "k_zones.plot(kind='bar')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "Instructions 2/2\n",
        "50 XP\n",
        "2\n",
        "Create a stacked bar plot of k_zones.\n",
        "Display the plot and examine it. Do you notice anything different about the data than you did previously?\n",
        "\n",
        "# Create a stacked bar plot of 'k_zones'\n",
        "k_zones.plot(kind='bar', stacked=True)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBeJyNVxV_rX"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Print the unique values in the stop_duration column. (This has been done for you.)\n",
        "Create a dictionary called mapping that maps the stop_duration strings to the integers specified above.\n",
        "Convert the stop_duration strings to integers using the mapping, and store the results in a new column called stop_minutes.\n",
        "Print the unique values in the stop_minutes column, to verify that the durations were properly converted to integers.\n",
        "\n",
        "# Print the unique values in 'stop_duration'\n",
        "print(ri.stop_duration.unique())\n",
        "\n",
        "# Create a dictionary that maps strings to integers\n",
        "mapping = {'0-15 Min':8, '16-30 Min':23, '30+ Min':45}\n",
        "\n",
        "# Convert the 'stop_duration' strings to integers using the 'mapping'\n",
        "ri['stop_minutes'] = ri.stop_duration.map(mapping)\n",
        "\n",
        "# Print the unique values in 'stop_minutes'\n",
        "print(ri.stop_minutes.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4txqmlkXWSC"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "For each value in the ri DataFrame's violation_raw column, calculate the mean number of stop_minutes that a driver is detained.\n",
        "Save the resulting Series as a new object, stop_length.\n",
        "Sort stop_length by its values, and then visualize it using a horizontal bar plot.\n",
        "Display the plot.\n",
        "\n",
        "# Calculate the mean 'stop_minutes' for each value in 'violation_raw'\n",
        "print(ri.groupby('violation_raw').stop_minutes.mean())\n",
        "\n",
        "# Save the resulting Series as 'stop_length'\n",
        "stop_length = ri.groupby('violation_raw').stop_minutes.mean()\n",
        "\n",
        "# Sort 'stop_length' by its values and create a horizontal bar plot\n",
        "stop_length.sort_values().plot(kind='barh')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiKTYioVYgKj"
      },
      "source": [
        "4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5qcxb1FXc0w"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "For each value in the ri DataFrame's violation_raw column, calculate the mean number of stop_minutes that a driver is detained.\n",
        "Save the resulting Series as a new object, stop_length.\n",
        "Sort stop_length by its values, and then visualize it using a horizontal bar plot.\n",
        "Display the plot.\n",
        "\n",
        "\n",
        "# Calculate the mean 'stop_minutes' for each value in 'violation_raw'\n",
        "print(ri.groupby('violation_raw').stop_minutes.mean())\n",
        "\n",
        "# Save the resulting Series as 'stop_length'\n",
        "stop_length = ri.groupby('violation_raw').stop_minutes.mean()\n",
        "\n",
        "# Sort 'stop_length' by its values and create a horizontal bar plot\n",
        "stop_length.sort_values().plot(kind='barh')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMMVL3UBZZ7s"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Read weather.csv into a DataFrame named weather.\n",
        "Select the temperature columns (TMIN, TAVG, TMAX) and print their summary statistics using the .describe() method.\n",
        "Create a box plot to visualize the temperature columns.\n",
        "Display the plot.\n",
        "\n",
        "# Read 'weather.csv' into a DataFrame named 'weather'\n",
        "weather = pd.read_csv('weather.csv')\n",
        "\n",
        "# Describe the temperature columns\n",
        "print(weather[['TMIN', 'TAVG', 'TMAX']].describe())\n",
        "\n",
        "# Create a box plot of the temperature columns\n",
        "weather[['TMIN', 'TAVG', 'TMAX']].plot(kind='box')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB7XS05MaFGZ"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a new column in the weather DataFrame named TDIFF that represents the difference between the maximum and minimum temperatures.\n",
        "Print the summary statistics for TDIFF using the .describe() method.\n",
        "Create a histogram with 20 bins to visualize TDIFF.\n",
        "Display the plot.\n",
        "\n",
        "# Create a 'TDIFF' column that represents temperature difference\n",
        "weather['TDIFF'] = weather.TMAX - weather.TMIN\n",
        "\n",
        "# Describe the 'TDIFF' column\n",
        "print(weather.TDIFF.describe())\n",
        "\n",
        "# Create a histogram with 20 bins to visualize 'TDIFF'\n",
        "weather.TDIFF.plot(kind='hist', bins=20)\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTBgie06mdLF"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Copy the columns WT01 through WT22 from weather to a new DataFrame named WT.\n",
        "Calculate the sum of each row in WT, and store the results in a new weather column named bad_conditions.\n",
        "Replace any missing values in bad_conditions with a 0. (This has been done for you.)\n",
        "Create a histogram to visualize bad_conditions, and then display the plot.\n",
        "\n",
        "# Copy 'WT01' through 'WT22' to a new DataFrame\n",
        "WT = weather.loc[:, 'WT01':'WT22']\n",
        "\n",
        "# Calculate the sum of each row in 'WT'\n",
        "weather['bad_conditions'] = WT.sum(axis='columns')\n",
        "\n",
        "# Replace missing values in 'bad_conditions' with '0'\n",
        "weather['bad_conditions'] = weather.bad_conditions.fillna(0).astype('int')\n",
        "\n",
        "# Create a histogram to visualize 'bad_conditions'\n",
        "weather.bad_conditions.plot(kind='hist')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHHHRZektJXr"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Count the unique values in the bad_conditions column and sort the index. (This has been done for you.)\n",
        "Create a dictionary called mapping that maps the bad_conditions integers to strings as specified above.\n",
        "Convert the bad_conditions integers to strings using the mapping and store the results in a new column called rating.\n",
        "Count the unique values in rating to verify that the integers were properly converted to strings.\n",
        "\n",
        "# Count the unique values in 'bad_conditions' and sort the index\n",
        "print(weather.bad_conditions.value_counts().sort_index())\n",
        "\n",
        "# Create a dictionary that maps integers to strings\n",
        "mapping = {0:'good', 1:'bad', 2:'bad', 3:'bad', 4:'bad', 5:'worse', 6:'worse', 7:'worse', 8:'worse', 9:'worse'}\n",
        "\n",
        "# Convert the 'bad_conditions' integers to strings using the 'mapping'\n",
        "weather['rating'] = weather.bad_conditions.map(mapping)\n",
        "\n",
        "# Count the unique values in 'rating'\n",
        "print(weather.rating.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeF5tHjN3dnl"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Create a list object called cats that lists the weather ratings in a logical order: 'good', 'bad', 'worse'.\n",
        "Change the data type of the rating column from object to category. Make sure to use the cats list to define the category ordering.\n",
        "Examine the head of the rating column to confirm that the categories are logically ordered.\n",
        "\n",
        "# Create a list of weather ratings in logical order\n",
        "cats= ['good', 'bad', 'worse']\n",
        "\n",
        "# Change the data type of 'rating' to category\n",
        "weather['rating'] = weather.rating.astype('category', ordered=True, categories=cats)\n",
        "\n",
        "# Examine the head of 'rating'\n",
        "print(weather.rating.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGfvtT3y-u6R"
      },
      "source": [
        "eset the index of the ri DataFrame.\n",
        "Examine the head of ri to verify that stop_datetime is now a DataFrame column, and the index is now the default integer index.\n",
        "Create a new DataFrame named weather_rating that contains only the DATE and rating columns from the weather DataFrame.\n",
        "Examine the head of weather_rating to verify that it contains the proper columns.\n",
        "\n",
        "# Reset the index of 'ri'\n",
        "ri.reset_index(inplace=True)\n",
        "\n",
        "# Examine the head of 'ri'\n",
        "print(ri.head())\n",
        "\n",
        "# Create a DataFrame from the 'DATE' and 'rating' columns\n",
        "weather_rating = weather[['DATE', 'rating']]\n",
        "\n",
        "# Examine the head of 'weather_rating'\n",
        "print(weather_rating.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmR6WOSpGf3W"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Examine the shape of the ri DataFrame.\n",
        "Merge the ri and weather_rating DataFrames using a left join.\n",
        "Examine the shape of ri_weather to confirm that it has two more columns but the same number of rows as ri.\n",
        "Replace the index of ri_weather with the stop_datetime column.\n",
        "\n",
        "# Examine the shape of 'ri'\n",
        "print(ri.shape)\n",
        "\n",
        "# Merge 'ri' and 'weather_rating' using a left join\n",
        "ri_weather = pd.merge(left=ri, right=weather_rating, left_on='stop_date', right_on='DATE', how='left')\n",
        "\n",
        "# Examine the shape of 'ri_weather'\n",
        "print(ri_weather.shape)\n",
        "\n",
        "# Set 'stop_datetime' as the index of 'ri_weather'\n",
        "ri_weather.set_index('stop_datetime', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARzWO62gG4VE"
      },
      "source": [
        "Instructions 1/3\n",
        "35 XP\n",
        "1\n",
        "Calculate the overall arrest rate by taking the mean of the is_arrested Series.\n",
        "\n",
        "# Calculate the overall arrest rate\n",
        "print(ri_weather.is_arrested.mean())\n",
        "\n",
        "Instructions 2/3\n",
        "35 XP\n",
        "Calculate the overall arrest rate by taking the mean of the is_arrested Series.\n",
        "\n",
        "2\n",
        "Calculate the arrest rate for each weather rating using a .groupby().\n",
        "\n",
        "# Calculate the arrest rate for each 'rating'\n",
        "print(ri_weather.groupby('rating').is_arrested.mean())\n",
        "\n",
        "3\n",
        "Calculate the arrest rate for each combination of violation and rating. How do the arrest rates differ by group?\n",
        "\n",
        "# Calculate the arrest rate for each 'violation' and 'rating'\n",
        "print(ri_weather.groupby(['violation', 'rating']).is_arrested.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBKXDqPHI370"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Save the output of the .groupby() operation from the last exercise as a new object, arrest_rate. (This has been done for you.)\n",
        "Print the arrest_rate Series and examine it.\n",
        "Print the arrest rate for moving violations in bad weather.\n",
        "Print the arrest rates for speeding violations in all three weather conditions.\n",
        "\n",
        "# Save the output of the groupby operation from the last exercise\n",
        "arrest_rate = ri_weather.groupby(['violation', 'rating']).is_arrested.mean()\n",
        "\n",
        "# Print the 'arrest_rate' Series\n",
        "print(arrest_rate)\n",
        "\n",
        "# Print the arrest rate for moving violations in bad weather\n",
        "print(arrest_rate.loc['Moving violation', 'bad'])\n",
        "\n",
        "# Print the arrest rates for speeding violations in all three weather conditions\n",
        "print(arrest_rate.loc['Speeding'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOrVTPhoKJiR"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Unstack the arrest_rate Series to reshape it into a DataFrame.\n",
        "Create the exact same DataFrame using a pivot table! Each of the three .pivot_table() parameters should be specified as one of the ri_weather columns.\n",
        "\n",
        "# Unstack the 'arrest_rate' Series into a DataFrame\n",
        "print(arrest_rate.unstack())\n",
        "\n",
        "# Create the same DataFrame using a pivot table\n",
        "print(ri_weather.pivot_table(index='violation', columns='rating', values='is_arrested'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}