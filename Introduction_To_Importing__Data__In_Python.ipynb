{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_To_Importing_ Data_ In_Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF2wwkWY1U55Efmv/IOe/4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Introduction_To_Importing__Data__In_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo8JC4wfp8A5"
      },
      "source": [
        "INTRODUCTION TO IMPORTING DATA IN PYTHON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff97RgpRqXAe"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Open the file moby_dick.txt as read-only and store it in the variable file. Make sure to pass the filename enclosed in quotation marks ''.\n",
        "Print the contents of the file to the shell using the print() function. As Hugo showed in the video, you'll need to apply the method read() to the object file.\n",
        "Check whether the file is closed by executing print(file.closed).\n",
        "Close the file using the close() method.\n",
        "Check again that the file is closed as you did above.\n",
        "\n",
        "# Open a file: file\n",
        "file = open('moby_dick.txt', mode='r')\n",
        "\n",
        "# Print it\n",
        "print(file.read())\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)\n",
        "\n",
        "# Close file\n",
        "file.close()\n",
        "\n",
        "# Check whether file is closed\n",
        "print(file.closed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMfz2fZjsWj5"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Open moby_dick.txt using the with context manager and the variable file.\n",
        "Print the first three lines of the file to the shell by using readline() three times within the context manager.\n",
        "\n",
        "# Read & print the first 3 lines\n",
        "with open('moby_dick.txt') as file:\n",
        "    print(file.readline())\n",
        "    print(file.readline())\n",
        "    print(file.readline())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yyi961OvjIt"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fill in the arguments of np.loadtxt() by passing file and a comma ',' for the delimiter.\n",
        "Fill in the argument of print() to print the type of the object digits. Use the function type().\n",
        "Execute the rest of the code to visualize one of the rows of the data.\n",
        "\n",
        "# Import package\n",
        "import numpy as np\n",
        "\n",
        "# Assign filename to variable: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Load file as array: digits\n",
        "digits = np.loadtxt(file, delimiter=',')\n",
        "\n",
        "# Print datatype of digits\n",
        "print(type(digits))\n",
        "\n",
        "# Select and reshape a row\n",
        "im = digits[21, 1:]\n",
        "im_sq = np.reshape(im, (28, 28))\n",
        "\n",
        "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
        "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl7kY_6fwRxg"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the arguments of np.loadtxt(): the file you're importing is tab-delimited, you want to skip the first row and you only want to import the first and third columns.\n",
        "Complete the argument of the print() call in order to print the entire array that you just imported.\n",
        "\n",
        "# Import numpy\n",
        "import numpy as np\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'digits_header.txt'\n",
        "\n",
        "# Load the data: data\n",
        "data = np.loadtxt(file, delimiter='\\t', skiprows=1, usecols=[0, 2])\n",
        "\n",
        "# Print data\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW9tQHev2JVH"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the first call to np.loadtxt() by passing file as the first argument.\n",
        "Execute print(data[0]) to print the first element of data.\n",
        "Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row.\n",
        "Print the 10th element of data_float by completing the print() command. Be guided by the previous print() call.\n",
        "Execute the rest of the code to visualize the data.\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'seaslug.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
        "\n",
        "# Print the first element of data\n",
        "print(data[0])\n",
        "\n",
        "# Import data as floats and skip the first row: data_float\n",
        "data_float = np.loadtxt(file, delimiter='\\t', dtype=float, skiprows=1)\n",
        "\n",
        "# Print the 10th element of data_float\n",
        "print(data_float[9])\n",
        "\n",
        "# Plot a scatterplot of the data\n",
        "plt.scatter(data_float[:, 0], data_float[:, 1])\n",
        "plt.xlabel('time (min.)')\n",
        "plt.ylabel('percentage of larvae')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCvhiyTm275M"
      },
      "source": [
        "Instructions\n",
        "0 XP\n",
        "Import titanic.csv using the function np.recfromcsv() and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None!\n",
        "Run the remaining code to print the first three entries of the resulting array d.\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Import file using np.recfromcsv: d\n",
        "d = np.recfromcsv(file)\n",
        "\n",
        "# Print out first three entries of d\n",
        "\n",
        "print(d[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHdpFVmw3TQ-"
      },
      "source": [
        "Instructions\n",
        "0 XP\n",
        "Import the pandas package using the alias pd.\n",
        "Read titanic.csv into a DataFrame called df. The file name is already stored in the file object.\n",
        "In a print() call, view the head of the DataFrame.\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'titanic.csv'\n",
        "\n",
        "# Read the file into a DataFrame: df\n",
        "df = pd.read_csv(file)\n",
        "\n",
        "# View the head of the DataFrame\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g__YQP6-4v_8"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the first 5 rows of the file into a DataFrame using the function pd.read_csv() and assign the result to data. You'll need to use the arguments nrows and header (there is no header in this file).\n",
        "Build a numpy array from the resulting DataFrame in data and assign to data_array.\n",
        "Execute print(type(data_array)) to print the datatype of data_array.\n",
        "\n",
        "# Assign the filename: file\n",
        "file = 'digits.csv'\n",
        "\n",
        "# Read the first 5 rows of the file into a DataFrame: data\n",
        "data = pd.read_csv(file, nrows=5, header=None)\n",
        "\n",
        "# Build a numpy array from the DataFrame: data_array\n",
        "data_array = data.values\n",
        "\n",
        "# Print the datatype of data_array to the shell\n",
        "print(type(data_array))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpMN3mac4-Cj"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'.\n",
        "Execute the rest of the code to print the head of the resulting DataFrame and plot the histogram of the 'Age' of passengers aboard the Titanic.\n",
        "\n",
        "# Import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'titanic_corrupt.txt'\n",
        "\n",
        "# Import file: data\n",
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values=['Nothing'])\n",
        "\n",
        "# Print the head of the DataFrame\n",
        "print(data.head())\n",
        "\n",
        "# Plot 'Age' variable in a histogram\n",
        "pd.DataFrame.hist(data[['Age']])\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y_JbeON5Fxo"
      },
      "source": [
        "Instructions\n",
        "0 XP\n",
        "Import the pickle package.\n",
        "Complete the second argument of open() so that it is read only for a binary file. This argument will be a string of two letters, one signifying 'read only', the other 'binary'.\n",
        "Pass the correct argument to pickle.load(); it should use the variable that is bound to open.\n",
        "Print the data, d.\n",
        "Print the datatype of d; take your mind back to your previous use of the function type()\n",
        "\n",
        "# Import pickle package\n",
        "import pickle\n",
        "\n",
        "# Open pickle file and load data\n",
        "with open('data.pkl', 'rb') as file:\n",
        "    d = pickle.load(file)\n",
        "\n",
        "# Print data\n",
        "print(d)\n",
        "\n",
        "# Print datatype\n",
        "print(type(d))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZlwsaNJLJZ"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Assign the spreadsheet filename (provided above) to the variable file.\n",
        "Pass the correct argument to pd.ExcelFile() to load the file using pandas, assigning the result to the variable xls.\n",
        "Print the sheetnames of the Excel spreadsheet by passing the necessary argument to the print() function.\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Assign spreadsheet filename: file\n",
        "file = 'battledeath.xlsx'\n",
        "\n",
        "# Load spreadsheet: xls\n",
        "xls = pd.ExcelFile(file)\n",
        "\n",
        "# Print sheet names\n",
        "print(xls.sheet_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MllY5VW0Km7m"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Load the sheet '2004' into the DataFrame df1 using its name as a string.\n",
        "Print the head of df1 to the shell.\n",
        "Load the sheet 2002 into the DataFrame df2 using its index (0).\n",
        "Print the head of df2 to the shell.\n",
        "\n",
        "# Load a sheet into a DataFrame by name: df1\n",
        "df1 = xls.parse('2004')\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Load a sheet into a DataFrame by index: df2\n",
        "df2 = xls.parse(0)\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMizyem5PXt4"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Parse the first sheet by index. In doing so, skip the first row of data and name the columns 'Country' and 'AAM due to War (2002)' using the argument names. The values passed to skiprows and names all need to be of type list.\n",
        "Parse the second sheet by index. In doing so, parse only the first column with the usecols parameter, skip the first row and rename the column 'Country'. The argument passed to usecols also needs to be of type list.\n",
        "\n",
        "# Parse the first sheet and rename the columns: df1\n",
        "df1 = xls.parse(0, skiprows=[0], names=['Country', 'AAM due to War (2002)'])\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "df2 = xls.parse(0, usecols=[0], skiprows=[0], names=['Country'])\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9bvR7mjSelv"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the module SAS7BDAT from the library sas7bdat.\n",
        "In the context of the file 'sales.sas7bdat', load its contents to a DataFrame df_sas, using the method to_data_frame() on the object file.\n",
        "Print the head of the DataFrame df_sas.\n",
        "Execute your entire script to produce a histogram plot!\n",
        "\n",
        "# Import sas7bdat package\n",
        "from sas7bdat import SAS7BDAT\n",
        "\n",
        "# Save file to a DataFrame: df_sas\n",
        "with SAS7BDAT('sales.sas7bdat') as file:\n",
        "    df_sas = file.to_data_frame()\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df_sas.head())\n",
        "\n",
        "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
        "pd.DataFrame.hist(df_sas[['P']])\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg1MP297bKYM"
      },
      "source": [
        "Instructions\n",
        "0 XP\n",
        "Use pd.read_stata() to load the file 'disarea.dta' into the DataFrame df.\n",
        "Print the head of the DataFrame df.\n",
        "Visualize your results by plotting a histogram of the column disa10. We’ve already provided this code for you, so just run it!\n",
        "\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Load Stata file into a pandas DataFrame: df\n",
        "df = pd.read_stata('disarea.dta')\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())\n",
        "\n",
        "# Plot histogram of one column of the DataFrame\n",
        "pd.DataFrame.hist(df[['disa10']])\n",
        "plt.xlabel('Extent of disease')\n",
        "plt.ylabel('Number of countries')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuZY1FUnb-WB"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the package h5py.\n",
        "Assign the name of the file to the variable file.\n",
        "Load the file as read only into the variable data.\n",
        "Print the datatype of data.\n",
        "Print the names of the groups in the HDF5 file 'LIGO_data.hdf5'.\n",
        "\n",
        "# Import packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "# Assign filename: file\n",
        "file = 'LIGO_data.hdf5'\n",
        "\n",
        "# Load file: data\n",
        "data = h5py.File(file, 'r')\n",
        "\n",
        "# Print the datatype of the loaded file\n",
        "print(type(data))\n",
        "\n",
        "# Print the keys of the file\n",
        "for key in data.keys():\n",
        "    print(key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxLCK7vTeIvf"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Assign the HDF5 group data['strain'] to group.\n",
        "In the for loop, print out the keys of the HDF5 group in group.\n",
        "Assign to the variable strain the values of the time series data data['strain']['Strain'] using the attribute .value.\n",
        "Set num_samples equal to 10000, the number of time points we wish to sample.\n",
        "Execute the rest of the code to produce a plot of the time series data in LIGO_data.hdf5.\n",
        "\n",
        "# Get the HDF5 group: group\n",
        "group = data['strain']\n",
        "\n",
        "# Check out keys of group\n",
        "for key in group.keys():\n",
        "    print(key)\n",
        "\n",
        "# Set variable equal to time series data: strain\n",
        "strain = data['strain']['Strain'].value\n",
        "\n",
        "# Set number of time points to sample: num_samples\n",
        "num_samples = 10000\n",
        "\n",
        "# Set time vector\n",
        "time = np.arange(0, 1, 1/num_samples)\n",
        "\n",
        "# Plot data\n",
        "plt.plot(time, strain[:num_samples])\n",
        "plt.xlabel('GPS Time (s)')\n",
        "plt.ylabel('strain')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG9sV4wqgvCw"
      },
      "source": [
        "Instructions\n",
        "0 XP\n",
        "Import the package scipy.io.\n",
        "Load the file 'albeck_gene_expression.mat' into the variable mat; do so using the function scipy.io.loadmat().\n",
        "Use the function type() to print the datatype of mat to the IPython shell.\n",
        "\n",
        "# Import package\n",
        "import scipy.io\n",
        "\n",
        "# Load MATLAB file: mat\n",
        "mat = scipy.io.loadmat('albeck_gene_expression.mat')\n",
        "\n",
        "# Print the datatype type of mat\n",
        "print(type(mat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk7fvGSipBZx"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Use the method .keys() on the dictionary mat to print the keys. Most of these keys (in fact the ones that do NOT begin and end with '__') are variables from the corresponding MATLAB environment.\n",
        "Print the type of the value corresponding to the key 'CYratioCyt' in mat. Recall that mat['CYratioCyt'] accesses the value.\n",
        "Print the shape of the value corresponding to the key 'CYratioCyt' using the numpy function shape().\n",
        "Execute the entire script to see some oscillatory gene expression data!\n",
        "\n",
        "# Print the keys of the MATLAB dictionary\n",
        "print(mat.keys())\n",
        "\n",
        "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
        "print(type(mat['CYratioCyt']))\n",
        "\n",
        "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
        "print(np.shape(mat['CYratioCyt']))\n",
        "\n",
        "# Subset the array and plot it\n",
        "data = mat['CYratioCyt'][25, 5:]\n",
        "fig = plt.figure()\n",
        "plt.plot(data)\n",
        "plt.xlabel('time (min.)')\n",
        "plt.ylabel('normalized fluorescence (measure of expression)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW7RzrwJyzt_"
      },
      "source": [
        "3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF0vc93Ry0X5"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the function create_engine from the module sqlalchemy.\n",
        "Create an engine to connect to the SQLite database 'Chinook.sqlite' and assign it to engine.\n",
        "\n",
        "# Import necessary module\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLa2xqGr4d4E"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the function create_engine from the module sqlalchemy.\n",
        "Create an engine to connect to the SQLite database 'Chinook.sqlite' and assign it to engine.\n",
        "Using the method table_names() on the engine engine, assign the table names of 'Chinook.sqlite' to the variable table_names.\n",
        "Print the object table_names to the shell.\n",
        "\n",
        "# Import necessary module\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Save the table names to a list: table_names\n",
        "table_names = engine.table_names()\n",
        "\n",
        "# Print the table names to the shell\n",
        "print(table_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3E28Yul-gAR"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Open the engine connection as con using the method connect() on the engine.\n",
        "Execute the query that selects ALL columns from the Album table. Store the results in rs.\n",
        "Store all of your query results in the DataFrame df by applying the fetchall() method to the results rs.\n",
        "Close the connection!\n",
        "\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine connection: con\n",
        "con = engine.connect()\n",
        "\n",
        "# Perform query: rs\n",
        "rs = con.execute(\"SELECT * FROM Album\")\n",
        "\n",
        "# Save results of the query to DataFrame: df\n",
        "df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "# Close connection\n",
        "con.close()\n",
        "\n",
        "# Print head of DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu7Ag3psC4Je"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Execute the SQL query that selects the columns LastName and Title from the Employee table. Store the results in the variable rs.\n",
        "Apply the method fetchmany() to rs in order to retrieve 3 of the records. Store them in the DataFrame df.\n",
        "Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\n",
        "\n",
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT LastName, Title FROM Employee\")\n",
        "    df = pd.DataFrame(rs.fetchmany(size=3))\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the length of the DataFrame df\n",
        "print(len(df))\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnMBbI7XLrgN"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Complete the argument of create_engine() so that the engine for the SQLite database 'Chinook.sqlite' is created.\n",
        "Execute the query that selects all records from the Employee table where 'EmployeeId' is greater than or equal to 6. Use the >= operator and assign the results to rs.\n",
        "Apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df.\n",
        "Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine in context manager\n",
        "# Perform query and save results to DataFrame: df\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT * FROM Employee WHERE EmployeeId >= 6\")\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print the head of the DataFrame df\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrfYEu3RZTrs"
      },
      "source": [
        "# Instructions\n",
        "# 100 XP\n",
        "# Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine.\n",
        "# In the context manager, execute the query that selects all records from the Employee table and orders them in increasing order by the column BirthDate. Assign the result to rs.\n",
        "# In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df.\n",
        "# Set the DataFrame's column names to the corresponding names of the table columns.\n",
        "\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///../_datasets/Chinook.sqlite')\n",
        "\n",
        "# Open engine in context manager\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute('SELECT * FROM Employee ORDER BY BirthDate')\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "    # Set the DataFrame's column names\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Open engine in context manager\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT * FROM Employee ORDER BY BirthDate\")\n",
        "    df = pd.DataFrame(rs.fetchall())\n",
        "\n",
        "    # Set the DataFrame's column names\n",
        "    df.columns = rs.keys()\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jCHqoYkdMNA"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the pandas package using the alias pd.\n",
        "Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine.\n",
        "Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select all records from the table Album.\n",
        "The remainder of the code is included to confirm that the DataFrame created by this method is equal to that created by the previous method that you learned.\n",
        "\n",
        "\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query(\"SELECT * FROM Album\", engine)\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Open engine in context manager and store query result in df1\n",
        "with engine.connect() as con:\n",
        "    rs = con.execute(\"SELECT * FROM Album\")\n",
        "    df1 = pd.DataFrame(rs.fetchall())\n",
        "    df1.columns = rs.keys()\n",
        "\n",
        "# Confirm that both methods yield the same result\n",
        "print(df.equals(df1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKsetvG7gAWG"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine.\n",
        "Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select all records from the Employee table where the EmployeeId is greater than or equal to 6 and ordered by BirthDate (make sure to use WHERE and ORDER BY in this precise order).\n",
        "\n",
        "\n",
        "# Import packages\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# Create engine: engine\n",
        "engine = create_engine('sqlite:///Chinook.sqlite')\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query(\n",
        "    \"SELECT * FROM Employee WHERE EmployeeId >= 6 ORDER BY BirthDate\",\n",
        "    engine\n",
        ")\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTSS3mJDopcp"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Assign to rs the results from the following query: select all the records, extracting the Title of the record and Name of the artist of each record from the Album table and the Artist table, respectively. To do so, INNER JOIN these two tables on the ArtistID column of both.\n",
        "In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df.\n",
        "Set the DataFrame's column names to the corresponding names of the table columns.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYC0Hd8Oov8A"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select all records from PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId that satisfy the condition Milliseconds < 250000.\n",
        "\n",
        "# Execute query and store records in DataFrame: df\n",
        "df = pd.read_sql_query(\n",
        "    \"SELECT * FROM PlaylistTrack INNER JOIN Track ON PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000\",\n",
        "    engine\n",
        ")\n",
        "\n",
        "# Print head of DataFrame\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2q_KICeo4lv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}