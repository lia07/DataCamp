{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Joining_Data_Wiht_Pandas.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Joining_Data_Wiht_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvkSjFLErVST"
      },
      "source": [
        "https://www.overleaf.com/project/602a3ad4719b74d31dec587a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyJ7aMkSrUgf"
      },
      "source": [
        "https://www.overleaf.com/project/602a3ad4719b74d31dec587a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBeHQV7YkV8d"
      },
      "source": [
        "Datacamp\n",
        "\n",
        "\n",
        "1. JOINING-DATA-WIHT-PANDAS\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9HhAmyDkQuu"
      },
      "source": [
        "# Merge the licenses and biz_owners table on account\n",
        "licenses_owners = licenses.merge(biz_owners, on='account')\n",
        "\n",
        "# Group the results by title then count the number of accounts\n",
        "counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
        "\n",
        "# Sort the counted_df in desending order\n",
        "sorted_df = counted_df.sort_values(by='account', ascending=False)\n",
        "\n",
        "# Use .head() method to print the first few rows of sorted_df\n",
        "print(sorted_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XISLAFhkeYt6"
      },
      "source": [
        "# Merge the ridership, cal, and stations tables\n",
        "ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
        "\t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
        "\n",
        "# Create a filter to filter ridership_cal_stations\n",
        "filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
        "                   & (ridership_cal_stations['day_type'] == 'Weekday') \n",
        "                   & (ridership_cal_stations['station_name'] == 'Wilson'))\n",
        "\n",
        "# Use .loc and the filter to select for rides\n",
        "print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVHBtSpStQc4"
      },
      "source": [
        "# Merge licenses and zip_demo, on zip; and merge the wards on ward\n",
        "licenses_zip_ward = licenses.merge(zip_demo, on='zip') \\\n",
        "            \t\t\t.merge(wards, on='ward')\n",
        "\n",
        "# Print the results by alderman and show median income\n",
        "print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DW6pwDHux8b"
      },
      "source": [
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on='ward') \\\n",
        "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1TrxnLGwoOn"
      },
      "source": [
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on='ward') \\\n",
        "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
        "\n",
        "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
        "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
        "                                   as_index=False).agg({'account':'count'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxSd-Ia0yh0f"
      },
      "source": [
        "# Merge land_use and census and merge result with licenses including suffixes\n",
        "land_cen_lic = land_use.merge(census, on='ward') \\\n",
        "                    .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
        "\n",
        "# Group by ward, pop_2010, and vacant, then count the # of accounts\n",
        "pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
        "                                   as_index=False).agg({'account':'count'})\n",
        "\n",
        "# Sort pop_vac_lic and print the results\n",
        "sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'], \n",
        "                                             ascending=[False, True, True])\n",
        "\n",
        "# Print the top few rows of sorted_pop_vac_lic\n",
        "print(sorted_pop_vac_lic.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEyygb-oK4Qc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "4fecc56d-3e35-46b5-b2ec-2c50eaed6b0b"
      },
      "source": [
        "# Merge the movies table with the financials table with a left join\n",
        "movies_financials = movies.merge(financials, on='id', how='left')\n",
        "\n",
        "# Count the number of rows in the budget column that are missing\n",
        "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
        "\n",
        "# Print the number of movies missing financials\n",
        "print(number_of_missing_fin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-32994e45c24d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Merge the movies table with the financials table with a left join\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmovies_financials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Count the number of rows in the budget column that are missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumber_of_missing_fin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies_financials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'budget'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'movies' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lizmM7duK3sg"
      },
      "source": [
        "# Merge the movies table with the financials table with a left join\n",
        "movies_financials = movies.merge(financials, on='id', how='left')\n",
        "\n",
        "# Count the number of rows in the budget column that are missing\n",
        "number_of_missing_fin = movies_financials['budget'].isnull().sum()\n",
        "\n",
        "# Print the number of movies missing financials\n",
        "print(number_of_missing_fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aov4IjvlVTYY"
      },
      "source": [
        "# Merge the toy_story and taglines tables with a inner join\n",
        "toystory_tag = toy_story.merge(taglines, on='id')\n",
        "\n",
        "# Print the rows and shape of toystory_tag\n",
        "print(toystory_tag)\n",
        "print(toystory_tag.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znB5NbP8VTRD"
      },
      "source": [
        "# Merge action_movies to scifi_movies with right join\n",
        "action_scifi = action_movies.merge(on='movie_id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfRMgGBJZkBB"
      },
      "source": [
        "# Merge action_movies to scifi_movies with right join\n",
        "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
        "                                   suffixes=('_act','_sci'))\n",
        "\n",
        "# Print the first few rows of action_scifi to see the structure\n",
        "print(action_scifi.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NoJbhL-aLgW"
      },
      "source": [
        "# Merge action_movies to the scifi_movies with right join\n",
        "action_scifi = action_movies.merge(scifi_movies, on='movie_id', how='right',\n",
        "                                   suffixes=('_act','_sci'))\n",
        "\n",
        "# From action_scifi, select only the rows where the genre_act column is null\n",
        "scifi_only = action_scifi[action_scifi['genre_act'].isnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8K93U3FavKj"
      },
      "source": [
        "# Use right join to merge the movie_to_genres and pop_movies tables\n",
        "genres_movies = movie_to_genres.merge(pop_movies, how='right', \n",
        "                                      left_on='movie_id', \n",
        "                                      right_on='id')\n",
        "\n",
        "# Count the number of genres\n",
        "genre_count = genres_movies.groupby('genre').agg({'id':'count'})\n",
        "\n",
        "# Plot a bar chart of the genre_count\n",
        "genre_count.plot(kind='bar')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQI_Gl0oUYf-"
      },
      "source": [
        "# Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
        "iron_1_and_2 = iron_1_actors.merge(iron_2_actors, \n",
        "                                     on='id', \n",
        "                                     how='outer', \n",
        "                                     suffixes=('_1','_2'))\n",
        "\n",
        "# Create an index that returns true if name_1 or name_2 are null\n",
        "m = ((iron_1_and_2['name_1'].isnull()) | \n",
        "     (iron_1_and_2['name_2'].isnull()))\n",
        "\n",
        "# Print the first few rows of iron_1_and_2\n",
        "print(iron_1_and_2[m].head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs8JfpMh5GpT"
      },
      "source": [
        "# Merge the crews table to itself\n",
        "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
        "                                suffixes=('_dir','_crew'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb5TFQ625H8r"
      },
      "source": [
        "# Merge the crews table to itself\n",
        "crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
        "                                suffixes=('_dir','_crew'))\n",
        "\n",
        "# Create a boolean index to select the appropriate rows\n",
        "boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n",
        "                  (crews_self_merged['job_crew'] != 'Director'))\n",
        "direct_crews = crews_self_merged[boolean_filter]\n",
        "\n",
        "# Print the first few rows of direct_crews\n",
        "print(direct_crews.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bp4yC7A5PqZ"
      },
      "source": [
        "# Merge to the movies table the ratings table on the index\n",
        "movies_ratings = movies.merge(ratings, left_on='id', right_on='movie_id', right_index=True)\n",
        "\n",
        "# Print the first few rows of movies_ratings\n",
        "print(movies_ratings.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYEnFX6ykx4e"
      },
      "source": [
        "# Merge the non_mus_tck and top_invoices tables on tid\n",
        "tracks_invoices = non_mus_tcks.merge(top_invoices, on='tid')\n",
        "\n",
        "# Use .isin() to subset non_mus_tcsk to rows with tid in tracks_invoices\n",
        "top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
        "\n",
        "# Group the top_tracks by gid and count the tid rows\n",
        "cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n",
        "\n",
        "# Merge the genres table to cnt_by_gid on gid and print\n",
        "print(cnt_by_gid.merge(genres, on='gid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoeQQJOiDEst"
      },
      "source": [
        "# Concatenate the tracks\n",
        "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st], \n",
        "                               sort=True)\n",
        "print(tracks_from_albums)\n",
        "\n",
        "# Concatenate the tracks so the index goes from 0 to n-1\n",
        "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
        "                               ignore_index=True,\n",
        "                               sort=True)\n",
        "print(tracks_from_albums)\n",
        "\n",
        "# Concatenate the tracks, show only columns names that are in all tables\n",
        "tracks_from_albums = pd.concat([tracks_master, tracks_ride, tracks_st],\n",
        "                               join='inner',\n",
        "                               sort=True)\n",
        "print(tracks_from_albums)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBTF7cmrIhSE"
      },
      "source": [
        "# Concatenate the tables and add keys\n",
        "inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
        "                            keys=['7Jul','8Aug','9Sep'])\n",
        "\n",
        "# Group the invoices by the index keys and find avg of the total column\n",
        "avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
        "\n",
        "# Bar plot of avg_inv_by_month\n",
        "avg_inv_by_month.plot(kind='bar')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc7nID4wVYew"
      },
      "source": [
        "# Use the .append() method to combine the tracks tables\n",
        "metallica_tracks = tracks_ride.append([tracks_master, tracks_st], sort=False)\n",
        "\n",
        "# Merge metallica_tracks and invoice_items\n",
        "tracks_invoices = metallica_tracks.merge(invoice_items, on='tid')\n",
        "\n",
        "# For each tid and name sum the quantity sold\n",
        "tracks_sold = tracks_invoices.groupby(['tid','name']).agg({'quantity':'sum'})\n",
        "\n",
        "# Sort in decending order by quantity and print the results\n",
        "print(tracks_sold.sort_values(['quantity'], ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEEfFsq8X3vw"
      },
      "source": [
        "# Concatenate the classic tables vertically\n",
        "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
        "\n",
        "# Concatenate the pop tables vertically\n",
        "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xMHYdl5YZU_"
      },
      "source": [
        "# Concatenate the classic tables vertically\n",
        "classic_18_19 = pd.concat([classic_18, classic_19], ignore_index=True)\n",
        "\n",
        "# Concatenate the pop tables vertically\n",
        "pop_18_19 = pd.concat([pop_18, pop_19], ignore_index=True)\n",
        "\n",
        "# Merge classic_18_19 with pop_18_19\n",
        "classic_pop = classic_18_19.merge(pop_18_19, on='tid')\n",
        "\n",
        "# Using .isin(), filter classic_18_19 rows where tid is in classic_pop\n",
        "popular_classic = classic_18_19[classic_18_19['tid'].isin(classic_pop['tid'])]\n",
        "\n",
        "# Print popular chart\n",
        "print(popular_classic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_tNE-qe5svG"
      },
      "source": [
        "# Use merge_ordered() to merge gdp and sp500 on year and date\n",
        "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
        "                             how='left')\n",
        "# Print gdp_sp500\n",
        "print(gdp_sp500)\n",
        "\n",
        "\n",
        "\n",
        "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
        "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
        "                             how='left',  fill_method='ffill')\n",
        "# Print gdp_sp500\n",
        "print (gdp_sp500)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt6LmVlbZONd",
        "outputId": "d93536ee-b3e9-475c-b7ce-1251b160130f"
      },
      "source": [
        "a = '{1,2,3,4}'\n",
        "print(type(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojV5OjC5m3Tn",
        "outputId": "5cf7e0ab-2c7d-455b-9814-a45cf8950375"
      },
      "source": [
        "print('Hello World!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY5Ud2QyziVr",
        "outputId": "d11e17c6-d79d-4e34-d8cd-b93e6495d349"
      },
      "source": [
        "\"0123456\".find('1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNm9-K6Y0Tu1",
        "outputId": "a78e3fb0-f6ac-4344-eda6-15e7822a79d6"
      },
      "source": [
        "B=[\"a\",\"b\",\"c\"]\n",
        "print(B[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['b', 'c']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVb3NMg40gXI",
        "outputId": "86f2887e-5871-4c5d-9b00-4b3b78b06451"
      },
      "source": [
        "name = 'Lizz'\n",
        "print(name[0:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Li\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5cVeJM1L4bo"
      },
      "source": [
        "# Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
        "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
        "                             how='left',  fill_method='ffill')\n",
        "\n",
        "# Subset the gdp and returns columns\n",
        "gdp_returns = gdp_sp500[['gdp','returns']]\n",
        "\n",
        "# Print gdp_returns correlation\n",
        "print(gdp_returns.corr())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax4ki8CR2PIs"
      },
      "source": [
        "# Use merge_ordered() to merge inflation, unemployment with inner join\n",
        "inflation_unemploy = pd.merge_ordered(inflation, unemployment, \n",
        "                                      on='date', how='inner')\n",
        "\n",
        "# Print inflation_unemploy \n",
        "print(inflation_unemploy)\n",
        "\n",
        "# Plot a scatter plot of unemployment_rate vs cpi of inflation_unemploy\n",
        "inflation_unemploy.plot(kind='scatter', x='unemployment_rate', y='cpi')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBM2k2Wz2S4O"
      },
      "source": [
        "# Merge gdp and pop on date and country with fill and notice rows 2 and 3\n",
        "ctry_date = pd.merge_ordered(gdp, pop, on=['date','country'], \n",
        "                             fill_method='ffill')\n",
        "\n",
        "# Print ctry_date\n",
        "print(ctry_date)\n",
        "\n",
        "\n",
        "# Merge gdp and pop on country and date with fill\n",
        "date_ctry = pd.merge_ordered(gdp, pop, on=['country','date'], \n",
        "                             fill_method='ffill')\n",
        "\n",
        "# Print date_ctry\n",
        "print(date_ctry)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bELp1ez3zOo"
      },
      "source": [
        "# Use merge_asof() to merge jpm and wells\n",
        "jpm_wells = pd.merge_asof(jpm, wells, on='date_time', \n",
        "                          suffixes=('', '_wells'), direction='nearest')\n",
        "\n",
        "# Use merge_asof() to merge jpm_wells and bac\n",
        "jpm_wells_bac = pd.merge_asof(jpm_wells, bac, on='date_time', \n",
        "                              suffixes=('_jpm', '_bac'), direction='nearest')\n",
        "\n",
        "# Compute price diff\n",
        "price_diffs = jpm_wells_bac.diff()\n",
        "\n",
        "# Plot the price diff of the close of jpm, wells and bac only\n",
        "price_diffs.plot(y=['close_jpm','close_wells','close_bac'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XINQdSaDGzz1"
      },
      "source": [
        "# Merge gdp and recession on date using merge_asof()\n",
        "gdp_recession = pd.merge_asof(gdp, recession, on='date')\n",
        "\n",
        "# Create a list based on the row value of gdp_recession['econ_status']\n",
        "is_recession = ['r' if s=='recession' else 'g' for s in gdp_recession['econ_status']]\n",
        "\n",
        "# Plot a bar chart of gdp_recession\n",
        "gdp_recession.plot(kind='bar', y='gdp', x='date', color=is_recession, rot=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H65XfEMff5Xh"
      },
      "source": [
        "# Merge gdp and pop on date and country with fill\n",
        "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
        "\n",
        "\n",
        "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
        "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY95fhnthoK3"
      },
      "source": [
        "# Merge gdp and pop on date and country with fill\n",
        "gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
        "\n",
        "# Add a column named gdp_per_capita to gdp_pop that divides the gdp by pop\n",
        "gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']\n",
        "\n",
        "# Pivot data so gdp_per_capita, where index is date and columns is country\n",
        "gdp_pivot = gdp_pop.pivot_table('gdp_per_capita', 'date', 'country')\n",
        "\n",
        "# Select dates equal to or greater than 1991-01-01\n",
        "recent_gdp_pop = gdp_pivot.query('date >= \"1991-01-01\"')\n",
        "\n",
        "# Plot recent_gdp_pop\n",
        "recent_gdp_pop.plot(rot=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9knLlqPemsjJ"
      },
      "source": [
        "# Unpivot everything besides the year column\n",
        "ur_tall = ur_wide.melt(id_vars=['year'], var_name='month', \n",
        "                       value_name='unempl_rate')\n",
        "\n",
        "# Create a date column using the month and year columns of ur_tall\n",
        "ur_tall['date'] = pd.to_datetime(ur_tall['month'] + '-' + ur_tall['year'])\n",
        "\n",
        "# Sort ur_tall by date in ascending order\n",
        "ur_sorted = ur_tall.sort_values('date')\n",
        "\n",
        "# Plot the unempl_rate by date\n",
        "ur_sorted.plot(x='date', y='unempl_rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Wh8oNzJnn2Y"
      },
      "source": [
        "# Use melt on ten_yr, unpivot everything besides the metric column\n",
        "bond_perc = ten_yr.melt(id_vars='metric', var_name='date', value_name='close')\n",
        "\n",
        "# Use query on bond_perc to select only the rows where metric=close\n",
        "bond_perc_close = bond_perc.query('metric == \"close\"')\n",
        "\n",
        "# Merge (ordered) dji and bond_perc_close on date with an inner join\n",
        "dow_bond = pd.merge_ordered(dji, bond_perc_close, on='date', \n",
        "                            suffixes=('_dow', '_bond'), how='inner')\n",
        "\n",
        "# Plot only the close_dow and close_bond columns\n",
        "dow_bond.plot(y=['close_dow', 'close_bond'], x='date', rot=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD5zPMA7kUub"
      },
      "source": [
        ""
      ]
    }
  ]
}