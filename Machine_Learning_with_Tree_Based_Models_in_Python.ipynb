{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning with Tree-Based Models in Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCep6rVA3lIPngaAJotgFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lia07/DataCamp/blob/main/Machine_Learning_with_Tree_Based_Models_in_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSxdnx-CZ8G_"
      },
      "source": [
        "Machine Learning with Tree-Based Models in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-bqE-OuaAPO"
      },
      "source": [
        "1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwyadvk0Z9pP"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeClassifier from sklearn.tree.\n",
        "\n",
        "Instantiate a DecisionTreeClassifier dt of maximum depth equal to 6.\n",
        "\n",
        "Fit dt to the training set.\n",
        "\n",
        "Predict the test set labels and assign the result to y_pred.\n",
        "\n",
        "\n",
        "# Import DecisionTreeClassifier from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
        "dt = DecisionTreeClassifier(max_depth=6, random_state=SEED)\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = dt.predict(X_test)\n",
        "print(y_pred[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3UbiBVUixmo"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the function accuracy_score from sklearn.metrics.\n",
        "Predict the test set labels and assign the obtained array to y_pred.\n",
        "Evaluate the test set accuracy score of dt by calling accuracy_score() and assign the value to acc.\n",
        "\n",
        "\n",
        "# Import accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute test set accuracy  \n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Test set accuracy: {:.2f}\".format(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t6AXqC4jlMg"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import LogisticRegression from sklearn.linear_model.\n",
        "Instantiate a LogisticRegression model and assign it to logreg.\n",
        "Fit logreg to the training set.\n",
        "Review the plot generated by plot_labeled_decision_regions().\n",
        "\n",
        "\n",
        "# Import LogisticRegression from sklearn.linear_model\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "\n",
        "# Instatiate logreg\n",
        "logreg = LogisticRegression(random_state=1)\n",
        "\n",
        "# Fit logreg to the training set\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Define a list called clfs containing the two classifiers logreg and dt\n",
        "clfs = [logreg, dt]\n",
        "\n",
        "# Review the decision regions of the two classifiers\n",
        "plot_labeled_decision_regions(X_test, y_test, clfs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4y7irUAvlwT"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeClassifier from sklearn.tree.\n",
        "Instantiate a DecisionTreeClassifier dt_entropy with a maximum depth of 8.\n",
        "Set the information criterion to 'entropy'.\n",
        "Fit dt_entropy on the training set.\n",
        "\n",
        "# Import DecisionTreeClassifier from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
        "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
        "\n",
        "# Fit dt_entropy to the training set\n",
        "dt_entropy.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgiBUYY2z6s9"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeClassifier from sklearn.tree.\n",
        "Instantiate a DecisionTreeClassifier dt_entropy with a maximum depth of 8.\n",
        "Set the information criterion to 'entropy'.\n",
        "Fit dt_entropy on the training set.\n",
        "\n",
        "\n",
        "# Import DecisionTreeClassifier from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
        "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
        "\n",
        "# Fit dt_entropy to the training set\n",
        "dt_entropy.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09W7lZWK45fk"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import accuracy_score from sklearn.metrics.\n",
        "Predict the test set labels of dt_entropy and assign the result to y_pred.\n",
        "Evaluate the test set accuracy of dt_entropy and assign the result to accuracy_entropy.\n",
        "Review accuracy_entropy and accuracy_gini.\n",
        "\n",
        "# Import accuracy_score from sklearn.metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Use dt_entropy to predict test set labels\n",
        "y_pred = dt_entropy.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy_entropy\n",
        "accuracy_entropy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy_entropy\n",
        "print('Accuracy achieved by using entropy: ', accuracy_entropy)\n",
        "\n",
        "# Print accuracy_gini\n",
        "print('Accuracy achieved by using the gini index: ', accuracy_gini)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhfSnkTr8ESC"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeRegressor from sklearn.tree.\n",
        "Instantiate a DecisionTreeRegressor dt with maximum depth 8 and min_samples_leaf set to 0.13.\n",
        "Fit dt to the training set.\n",
        "\n",
        "# Import DecisionTreeRegressor from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeRegressor(max_depth=8,\n",
        "                           min_samples_leaf=0.13,\n",
        "                           random_state=3)\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGQ8llBvA5Du"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeRegressor from sklearn.tree.\n",
        "Instantiate a DecisionTreeRegressor dt with maximum depth 8 and min_samples_leaf set to 0.13.\n",
        "Fit dt to the training set.\n",
        "\n",
        "# Import DecisionTreeRegressor from sklearn.tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeRegressor(max_depth=8,\n",
        "                           min_samples_leaf=0.13,\n",
        "                           random_state=3)\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpgkrgUbEXLQ"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import the function mean_squared_error as MSE from sklearn.metrics.\n",
        "Predict the test set labels and assign the output to y_pred.\n",
        "Compute the test set MSE by calling MSE and assign the result to mse_dt.\n",
        "Compute the test set RMSE and assign it to rmse_dt.\n",
        "\n",
        "# Import mean_squared_error from sklearn.metrics as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Compute y_pred\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute mse_dt\n",
        "mse_dt = MSE(y_test, y_pred)\n",
        "\n",
        "# Compute rmse_dt\n",
        "rmse_dt = mse_dt**(1/2)\n",
        "\n",
        "# Print rmse_dt\n",
        "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgfOh3IaEjSO"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Predict test set labels using the linear regression model (lr) and assign the result to y_pred_lr.\n",
        "\n",
        "Compute the test set MSE and assign the result to mse_lr.\n",
        "\n",
        "Compute the test set RMSE and assign the result to rmse_lr.\n",
        "\n",
        "\n",
        "# Predict test set labels \n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Compute mse_lr\n",
        "mse_lr = MSE(y_test, y_pred_lr)\n",
        "\n",
        "# Compute rmse_lr\n",
        "rmse_lr = mse_lr**(1/2)\n",
        "\n",
        "# Print rmse_lr\n",
        "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
        "\n",
        "# Print rmse_dt\n",
        "print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVrwYnkyExW5"
      },
      "source": [
        "2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwXM6zw3EuUi"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import train_test_split from sklearn.model_selection.\n",
        "Split the data into 70% train and 30% test.\n",
        "Instantiate a DecisionTreeRegressor with max depth 4 and min_samples_leaf set to 0.26.\n",
        "\n",
        "# Import train_test_split from sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set SEED for reproducibility\n",
        "SEED = 1\n",
        "\n",
        "# Split the data into 70% train and 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
        "\n",
        "# Instantiate a DecisionTreeRegressor dt\n",
        "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.26, random_state=SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcgH_CoVEzKO"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Compute dt's 10-fold cross-validated MSE by setting the scoring argument to 'neg_mean_squared_error'.\n",
        "Compute RMSE from the obtained MSE scores.\n",
        "Take Hint (-30 XP)\n",
        "\n",
        "\n",
        "# Compute the array containing the 10-folds CV MSEs\n",
        "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
        "                                  scoring='neg_mean_squared_error', \n",
        "                                  n_jobs=-1) \n",
        "\n",
        "# Compute the 10-folds CV RMSE\n",
        "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
        "\n",
        "# Print RMSE_CV\n",
        "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5FCVREEEy_Q"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import mean_squared_error as MSE from sklearn.metrics.\n",
        "Fit dt to the training set.\n",
        "Predict dt's training set labels and assign the result to y_pred_train.\n",
        "Evaluate dt's training set RMSE and assign it to RMSE_train.\n",
        "\n",
        "\n",
        "# Import mean_squared_error from sklearn.metrics as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Fit dt to the training set\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the training set\n",
        "y_pred_train = dt.predict(X_train)\n",
        "\n",
        "# Evaluate the training set RMSE of dt\n",
        "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
        "\n",
        "# Print RMSE_train\n",
        "print('Train RMSE: {:.2f}'.format(RMSE_train))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n62uMi_3Eyy2"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Instantiate a Logistic Regression classifier and assign it to lr.\n",
        "Instantiate a KNN classifier that considers 27 nearest neighbors and assign it to knn.\n",
        "Instantiate a Decision Tree Classifier with the parameter min_samples_leaf set to 0.13 and assign it to dt.\n",
        "\n",
        "# Set seed for reproducibility\n",
        "SEED=1\n",
        "\n",
        "# Instantiate lr\n",
        "lr = LogisticRegression(random_state=SEED)\n",
        "\n",
        "# Instantiate knn\n",
        "knn = KNN(n_neighbors=27)\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
        "\n",
        "# Define the list classifiers\n",
        "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gl8HFvr3Vfa"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Iterate over the tuples in classifiers. Use clf_name and clf as the for loop variables:\n",
        "Fit clf to the training set.\n",
        "Predict clf's test set labels and assign the results to y_pred.\n",
        "Evaluate the test set accuracy of clf and print the result.\n",
        "\n",
        "\n",
        " Iterate over the pre-defined list of classifiers\n",
        "for clf_name, clf in classifiers:    \n",
        "  \n",
        "    # Fit clf to the training set\n",
        "    clf.fit(X_train, y_train)    \n",
        "  \n",
        "    # Predict y_pred\n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "  \n",
        "    # Evaluate clf's accuracy on the test set\n",
        "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2uRaWsM3VNE"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import VotingClassifier from sklearn.ensemble.\n",
        "Instantiate a VotingClassifier by setting the parameter estimators to classifiers and assign it to vc.\n",
        "Fit vc to the training set.\n",
        "Evaluate vc's test set accuracy using the test set predictions y_pred.\n",
        "\n",
        "\n",
        "# Import VotingClassifier from sklearn.ensemble\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# Instantiate a VotingClassifier vc \n",
        "vc = VotingClassifier(estimators=classifiers)     \n",
        "\n",
        "# Fit vc to the training set\n",
        "vc.fit(X_train, y_train)   \n",
        "\n",
        "# Evaluate the test set predictions\n",
        "y_pred = vc.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Voting Classifier: {:.3f}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk0Em5OO89Vd"
      },
      "source": [
        "3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuVrYQO93VA3"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import DecisionTreeClassifier from sklearn.tree and BaggingClassifier from sklearn.ensemble.\n",
        "Instantiate a DecisionTreeClassifier called dt.\n",
        "Instantiate a BaggingClassifier called bc consisting of 50 trees.\n",
        "\n",
        "# Import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Import BaggingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Instantiate bc\n",
        "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuTLYYKE3Uzn"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit bc to the training set.\n",
        "Predict the test set labels and assign the result to y_pred.\n",
        "Determine bc's test set accuracy.\n",
        "\n",
        "# Fit bc to the training set\n",
        "bc.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = bc.predict(X_test)\n",
        "\n",
        "# Evaluate acc_test\n",
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "print('Test set accuracy of bc: {:.2f}'.format(acc_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_piUE_up3Ujv"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import BaggingClassifier from sklearn.ensemble.\n",
        "Instantiate a DecisionTreeClassifier with min_samples_leaf set to 8.\n",
        "Instantiate a BaggingClassifier consisting of 50 trees and set oob_score to True.\n",
        "\n",
        "\n",
        "# Import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Import BaggingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
        "\n",
        "# Instantiate bc\n",
        "bc = BaggingClassifier(base_estimator=dt, \n",
        "                       n_estimators=50,\n",
        "                       oob_score=True,\n",
        "                       random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38ZJ5LyAEyef"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit bc to the training set and predict the test set labels and assign the results to y_pred.\n",
        "Evaluate the test set accuracy acc_test by calling accuracy_score.\n",
        "Evaluate bc's OOB accuracy acc_oob by extracting the attribute oob_score_ from bc.\n",
        "\n",
        "\n",
        "# Fit bc to the training set \n",
        "bc.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = bc.predict(X_test)\n",
        "\n",
        "# Evaluate test set accuracy\n",
        "acc_test = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Evaluate OOB accuracy\n",
        "acc_oob = bc.oob_score_\n",
        "\n",
        "# Print acc_test and acc_oob\n",
        "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECKY_WFq46fy"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import RandomForestRegressor from sklearn.ensemble.\n",
        "Instantiate a RandomForestRegressor called rf consisting of 25 trees.\n",
        "Fit rf to the training set.\n",
        "\n",
        "\n",
        "# Import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Instantiate rf\n",
        "rf = RandomForestRegressor(n_estimators=25,\n",
        "            random_state=2)\n",
        "            \n",
        "# Fit rf to the training set    \n",
        "rf.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB_osoda45--"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import mean_squared_error from sklearn.metrics as MSE.\n",
        "Predict the test set labels and assign the result to y_pred.\n",
        "Compute the test set RMSE and assign it to rmse_test.\n",
        "\n",
        "\n",
        "# Import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Predict the test set labels\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the test set RMSE\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "\n",
        "# Print rmse_test\n",
        "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsC9IWL28Ss8"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Call the .sort_values() method on importances and assign the result to importances_sorted.\n",
        "Call the .plot() method on importances_sorted and set the arguments:\n",
        "kind to 'barh'\n",
        "color to 'lightgreen'\n",
        "\n",
        "# Create a pd.Series of features importances\n",
        "importances = pd.Series(data=rf.feature_importances_,\n",
        "                        index= X_train.columns)\n",
        "\n",
        "# Sort importances\n",
        "importances_sorted = importances.sort_values()\n",
        "\n",
        "# Draw a horizontal barplot of importances_sorted\n",
        "importances_sorted.plot(kind='barh', color='lightgreen')\n",
        "plt.title('Features Importances')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLHkEpYeBWIp"
      },
      "source": [
        "4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBWvPR2sBXS2"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import AdaBoostClassifier from sklearn.ensemble.\n",
        "Instantiate a DecisionTreeClassifier with max_depth set to 2.\n",
        "Instantiate an AdaBoostClassifier consisting of 180 trees and setting the base_estimator to dt.\n",
        "\n",
        "# Import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Import AdaBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Instantiate dt\n",
        "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
        "\n",
        "# Instantiate ada\n",
        "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eqVdu758SQ1"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit ada to the training set.\n",
        "Evaluate the probabilities of obtaining the positive class in the test set.\n",
        "\n",
        "# Fit ada to the training set\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "# Compute the probabilities of obtaining the positive class\n",
        "y_pred_proba = ada.predict_proba(X_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbQNLGcCJ0E"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import roc_auc_score from sklearn.metrics.\n",
        "Compute ada's test set ROC AUC score, assign it to ada_roc_auc, and print it out.\n",
        "\n",
        "# Import roc_auc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Evaluate test-set roc_auc_score\n",
        "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print roc_auc_score\n",
        "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkq-VnriDsZ6"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import GradientBoostingRegressor from sklearn.ensemble.\n",
        "Instantiate a gradient boosting regressor by setting the parameters:\n",
        "max_depth to 4\n",
        "n_estimators to 200\n",
        "\n",
        "# Import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate gb\n",
        "gb = GradientBoostingRegressor(max_depth=4,\n",
        "                               n_estimators=200,\n",
        "                               random_state=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k67s9yNY8SKs"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit gb to the training set.\n",
        "Predict the test set labels and assign the result to y_pred.\n",
        "\n",
        "# Fit gb to the training set\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = gb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrlqtWBDD-c2"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit gb to the training set.\n",
        "Predict the test set labels and assign the result to y_pred.\n",
        "\n",
        "\n",
        "# Fit gb to the training set\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = gb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXrkxR0HD-Eb"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import mean_squared_error from sklearn.metrics as MSE.\n",
        "Compute the test set MSE and assign it to mse_test.\n",
        "Compute the test set RMSE and assign it to rmse_test.\n",
        "\n",
        "# Import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Compute MSE\n",
        "mse_test = MSE(y_test, y_pred)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse_test = mse_test**(1/2)\n",
        "\n",
        "# Print RMSE\n",
        "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBP2dHDqEWnw"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Instantiate a Stochastic Gradient Boosting Regressor (SGBR) and set:\n",
        "max_depth to 4 and n_estimators to 200,\n",
        "subsample to 0.9, and\n",
        "max_features to 0.75.\n",
        "\n",
        "\n",
        "# Import GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Instantiate sgbr\n",
        "sgbr = GradientBoostingRegressor(max_depth=4, \n",
        "            subsample=0.9,\n",
        "            max_features=0.75,\n",
        "            n_estimators=200,                                \n",
        "            random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktIlF3FwEWgV"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Fit sgbr to the training set.\n",
        "Predict the test set labels and assign the results to y_pred.\n",
        "\n",
        "# Fit sgbr to the training set\n",
        "sgbr.fit(X_train, y_train)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = sgbr.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ANsu9ObEWc7"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import mean_squared_error as MSE from sklearn.metrics.\n",
        "Compute test set MSE and assign the result to mse_test.\n",
        "Compute test set RMSE and assign the result to rmse_test.\n",
        "\n",
        "# Import mean_squared_error as MSE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Compute test set MSE\n",
        "mse_test = MSE(y_test, y_pred)\n",
        "\n",
        "# Compute test set RMSE\n",
        "rmse_test = mse_test**(1/2)\n",
        "\n",
        "# Print rmse_test\n",
        "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia1bozIgO0t-"
      },
      "source": [
        "5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em1gWHYqEWPy"
      },
      "source": [
        "min_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_s9dGnuEV7N"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Define a grid of hyperparameters corresponding to a Python dictionary called params_dt with:\n",
        "the key 'max_depth' set to a list of values 2, 3, and 4\n",
        "the key 'min_samples_leaf' set to a list of values 0.12, 0.14, 0.16, 0.18\n",
        "\n",
        "\n",
        "# Define params_dt\n",
        "params_dt = {\n",
        "             'max_depth': [2, 3, 4],\n",
        "             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXgf4-6TO2qU"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import GridSearchCV from sklearn.model_selection.\n",
        "Instantiate a GridSearchCV object using 5-fold CV by setting the parameters:\n",
        "estimator to dt, param_grid to params_dt and\n",
        "scoring to 'roc_auc'.\n",
        "\n",
        "\n",
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Instantiate grid_dt\n",
        "grid_dt = GridSearchCV(estimator=dt,\n",
        "                       param_grid=params_dt,\n",
        "                       scoring='roc_auc',\n",
        "                       cv=5,\n",
        "                       n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1enXq5OEVuS"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import roc_auc_score from sklearn.metrics.\n",
        "Extract the .best_estimator_ attribute from grid_dt and assign it to best_model.\n",
        "Predict the test set probabilities of obtaining the positive class y_pred_proba.\n",
        "Compute the test set ROC AUC score test_roc_auc of best_model.\n",
        "\n",
        "# Import roc_auc_score from sklearn.metrics \n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Extract the best estimator\n",
        "best_model = grid_dt.best_estimator_\n",
        "\n",
        "# Predict the test set probabilities of the positive class\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "# Compute test_roc_auc\n",
        "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "# Print test_roc_auc\n",
        "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdCdaDJKVDlf"
      },
      "source": [
        "\n",
        "learning_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms19IPnTZtv7"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Define a grid of hyperparameters corresponding to a Python dictionary called params_rf with:\n",
        "the key 'n_estimators' set to a list of values 100, 350, 500\n",
        "the key 'max_features' set to a list of values 'log2', 'auto', 'sqrt'\n",
        "the key 'min_samples_leaf' set to a list of values 2, 10, 30\n",
        "\n",
        "# Define the dictionary 'params_rf'\n",
        "params_rf = {\n",
        "             'n_estimators': [100, 350, 500],\n",
        "             'max_features': ['log2', 'auto', 'sqrt'],\n",
        "             'min_samples_leaf': [2, 10, 30], \n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjT0qXPDZtYd"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import GridSearchCV from sklearn.model_selection.\n",
        "Instantiate a GridSearchCV object using 3-fold CV by using negative mean squared error as the scoring metric.\n",
        "\n",
        "# Import GridSearchCV\n",
        "from sklearn.model_selection import  GridSearchCV\n",
        "\n",
        "# Instantiate grid_rf\n",
        "grid_rf = GridSearchCV(estimator=rf,\n",
        "                       param_grid=params_rf,\n",
        "                       scoring='neg_mean_squared_error',\n",
        "                       cv=3,\n",
        "                       verbose=1,\n",
        "                       n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBKHz7ImaeXg"
      },
      "source": [
        "Instructions\n",
        "100 XP\n",
        "Import mean_squared_error as MSE from sklearn.metrics.\n",
        "Extract the best estimator from grid_rf and assign it to best_model.\n",
        "Predict best_model's test set labels and assign the result to y_pred.\n",
        "Compute best_model's test set RMSE.\n",
        "\n",
        "\n",
        "# Import mean_squared_error from sklearn.metrics as MSE \n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "\n",
        "# Extract the best estimator\n",
        "best_model = grid_rf.best_estimator_\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Compute rmse_test\n",
        "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
        "\n",
        "# Print rmse_test\n",
        "print('Test RMSE of best model: {:.3f}'.format(rmse_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}